{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "StarGAN_Spectrogram2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rPo7c63klQ4",
        "outputId": "67e6ad21-b486-4677-ef52-5656e4036719"
      },
      "source": [
        "!pip install torchaudio"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchaudio\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/aa/55/01ad9244bcd595e39cea5ce30726a7fe02fd963d07daeb136bfe7e23f0a5/torchaudio-0.8.1-cp37-cp37m-manylinux1_x86_64.whl (1.9MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9MB 18.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch==1.8.1 in /usr/local/lib/python3.7/dist-packages (from torchaudio) (1.8.1+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1->torchaudio) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1->torchaudio) (3.7.4.3)\n",
            "Installing collected packages: torchaudio\n",
            "Successfully installed torchaudio-0.8.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fljm8mupduwP"
      },
      "source": [
        "import torchaudio\n",
        "import torchvision\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import IterableDataset, DataLoader\n",
        "from torch.backends import cudnn\n",
        "import numpy as np\n",
        "import glob\n",
        "import os\n",
        "from sklearn.metrics import confusion_matrix\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I75OU-XZkq1P",
        "outputId": "ac665f10-4ac2-4ff6-82f4-b281b6748d57"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('./drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at ./drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lNs4Dscxyw0"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0hsUsw7iFMz"
      },
      "source": [
        "SPEC_DATASET_PATH = \"./drive/MyDrive/cs753 dataset/spectrograms/\"\n",
        "AUDIO_DATASET_PATH = \"./drive/MyDrive/cs753 dataset/audio/\"\n",
        "MODEL_SAVE_PATH = \"./drive/MyDrive/cs753 dataset/\"\n",
        "MODEL_FILENAME = \"stargan_spectrograms2.pt\"\n",
        "\n",
        "INSTRUMENTS = [\n",
        "    \"Bansuri\",\n",
        "    \"Shehnai\",\n",
        "    \"Santoor\",\n",
        "    \"Sarod\",\n",
        "    \"Violin\"\n",
        "]\n",
        "\n",
        "INSTRUMENT_LABELS = {\n",
        "    \"Bansuri\" : 0,\n",
        "    \"Shehnai\" : 1,\n",
        "    \"Santoor\" : 2,\n",
        "    \"Sarod\"   : 3,\n",
        "    \"Violin\"  : 4\n",
        "}\n",
        "\n",
        "WEIGHT = np.array([\n",
        "    891,\n",
        "    1664,\n",
        "    1122,\n",
        "    765,\n",
        "    1193\n",
        "])\n",
        "WEIGHT = torch.tensor((WEIGHT / (WEIGHT.sum())) ** -1)\n",
        "WEIGHT = WEIGHT.float().to(device)\n",
        "\n",
        "spec_files_path = os.path.join(SPEC_DATASET_PATH, \"*.pt\")\n",
        "audio_files_path = os.path.join(AUDIO_DATASET_PATH, \"*.pt\")\n",
        "SPEC_FILES = sorted(glob.glob(spec_files_path))\n",
        "AUDIO_FILES = sorted(glob.glob(audio_files_path))\n",
        "NUM_FILES = len(SPEC_FILES)\n",
        "\n",
        " \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8u9jcGT0B00",
        "outputId": "c980b132-705b-4d37-99d8-022f63154f44"
      },
      "source": [
        "print(NUM_FILES)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5637\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbjimf6HeKyy"
      },
      "source": [
        "def normalize(data):\n",
        "  data = data.type(torch.FloatTensor).unsqueeze(0)\n",
        "  mean = data.mean(dim=2).unsqueeze(2)\n",
        "  std = data.std(dim=2).unsqueeze(2)\n",
        "  indices = (std == 0)\n",
        "  std[indices] = 1\n",
        "  data = (data - mean) / std\n",
        "  std[indices] = 0\n",
        "  return data, mean, std"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5H0lqA0_YAbs"
      },
      "source": [
        "def label2onehot(labels, dim):\n",
        "  \"\"\"Convert label indices to one-hot vectors.\"\"\"\n",
        "  batch_size = labels.size(0)\n",
        "  out = torch.zeros(batch_size, dim)\n",
        "  out[np.arange(batch_size), labels.long()] = 1\n",
        "  return out\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97ujdlVjlqw6"
      },
      "source": [
        "def gradient_penalty(y, x):\n",
        "  \"\"\"Compute gradient penalty: (L2_norm(dy/dx) - 1)**2.\"\"\"\n",
        "  weight = torch.ones(y.size(), device=device)\n",
        "  dydx = torch.autograd.grad(outputs=y,\n",
        "                              inputs=x,\n",
        "                              grad_outputs=weight,\n",
        "                              retain_graph=True,\n",
        "                              create_graph=True,\n",
        "                              only_inputs=True)[0]\n",
        "\n",
        "  dydx = dydx.view(dydx.size(0), -1)\n",
        "  dydx_l2norm = torch.sqrt(torch.sum(dydx**2, dim=1))\n",
        "  return torch.mean((dydx_l2norm-1)**2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPoaAcId1loM"
      },
      "source": [
        "class DataSource:\n",
        "\n",
        "  def __init__(self, batch_size=4):\n",
        "    self.order = np.random.permutation(NUM_FILES)\n",
        "    self.batch_size = batch_size\n",
        "    self.counter = 0\n",
        "\n",
        "  def __next__(self):\n",
        "    if self.counter >= NUM_FILES:\n",
        "      self.order = np.random.permutation(NUM_FILES)\n",
        "      self.counter = 0\n",
        "      raise StopIteration()\n",
        "    file_indices = self.order[self.counter:self.counter+self.batch_size]\n",
        "    self.counter += self.batch_size\n",
        "    x_tensor_list = []\n",
        "    y_tensor_list = []\n",
        "    spec_tensor_list = []\n",
        "    for index in file_indices:\n",
        "      audio_filename = AUDIO_FILES[index]\n",
        "      spec_filename = SPEC_FILES[index]\n",
        "      data = torch.load(audio_filename)\n",
        "      d = torch.load(spec_filename)\n",
        "      label = d['y'] \n",
        "      # spec = d['x']\n",
        "      # spec, _, _ = normalize(spec.squeeze(0))\n",
        "      x_tensor_list.append(data)\n",
        "      y_tensor_list.append(label)\n",
        "      # spec_tensor_list.append(spec)\n",
        "    X = torch.vstack(x_tensor_list)\n",
        "    # print(y_tensor_list[0].shape)\n",
        "    y = torch.tensor(y_tensor_list)\n",
        "    # s = torch.vstack(spec_tensor_list)\n",
        "    y_perm = (y.clone() + torch.randint(1, 5, size=[y.shape[0]])) % 5\n",
        "    # return X, y, y_perm, s\n",
        "    return X, y, y_perm, torch.tensor([1])\n",
        "\n",
        "class MyIterableDataset(IterableDataset):\n",
        "\n",
        "  def __init__(self, batch_size=4):\n",
        "    self.source = DataSource(batch_size)\n",
        "\n",
        "  def __iter__(self):\n",
        "    return self.source\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8f2ZBdSZ1cM"
      },
      "source": [
        "class Backbone(nn.Module):\n",
        "  \"\"\" Feature Extraction Network\"\"\" \n",
        "  def __init__(self): \n",
        "    super(Backbone, self).__init__() \n",
        "    layers = [] \n",
        "    layers.append(nn.Conv2d(2, 32, [5,41], [3,21])) \n",
        "    layers.append(nn.InstanceNorm2d(32)) \n",
        "    layers.append(nn.LeakyReLU(0.01)) \n",
        "    layers.append(nn.Conv2d(32, 64, 5, 3)) \n",
        "    layers.append(nn.InstanceNorm2d(64)) \n",
        "    layers.append(nn.LeakyReLU(0.01)) \n",
        "    layers.append(nn.Conv2d(64, 128, 4, 2)) \n",
        "    layers.append(nn.InstanceNorm2d(32))         \n",
        "    layers.append(nn.LeakyReLU(0.01)) \n",
        "    self.main = nn.Sequential(*layers) \n",
        "      \n",
        "  def forward(self, x): \n",
        "    return self.main(x)\n",
        "\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "  \"\"\" Classification head for the backbone \"\"\"\n",
        "  def __init__(self): \n",
        "    super(Classifier, self).__init__() \n",
        "    self.bb = Backbone() \n",
        "    self.conv = nn.Conv2d(128, 5, [9,11], 1) \n",
        "      \n",
        "  def forward(self, x): \n",
        "    x = self.bb(x) \n",
        "    x = self.conv(x) \n",
        "    y = x.view(x.shape[0], x.shape[1])\n",
        "    return y\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "  \"\"\" Discrimination head for the backbone \"\"\"\n",
        "  def __init__(self): \n",
        "    super(Discriminator, self).__init__() \n",
        "    self.bb = Backbone() \n",
        "    self.disc = nn.Conv2d(128, 1, [9,11], 1) \n",
        "      \n",
        "  def forward(self, x): \n",
        "    x = self.bb(x) \n",
        "    x = self.disc(x) \n",
        "    y = x.view(x.shape[0], x.shape[1])\n",
        "    return y\n",
        "\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "  \"\"\"Residual Block with instance normalization.\"\"\"\n",
        "  def __init__(self, dim_in, dim_out):\n",
        "    super(ResidualBlock, self).__init__()\n",
        "    self.main = nn.Sequential(\n",
        "      nn.Conv1d(dim_in, dim_out, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "      nn.LeakyReLU(0.01),\n",
        "      nn.Conv1d(dim_out, dim_out, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "    )\n",
        "    self.relu = nn.LeakyReLU(0.01)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.relu(x + self.main(x))\n",
        "\n",
        "\n",
        "class Generator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Generator, self).__init__()\n",
        "    layers = [\n",
        "      nn.Conv1d(7, 32, 400, 50, padding=200),\n",
        "      nn.LeakyReLU(0.01),\n",
        "      nn.Conv1d(32, 64, 5, 2, padding=2),\n",
        "      nn.LeakyReLU(0.01),\n",
        "      nn.Conv1d(64, 128, 5, 2, padding=2),\n",
        "      nn.LeakyReLU(0.01),\n",
        "      ResidualBlock(128, 128),\n",
        "      ResidualBlock(128, 128),\n",
        "      ResidualBlock(128, 128),\n",
        "      ResidualBlock(128, 128),\n",
        "      nn.ConvTranspose1d(128, 64, 5, 2, padding=2),\n",
        "      nn.LeakyReLU(0.01),\n",
        "      nn.ConvTranspose1d( 64, 32, 5, 2, padding=2),\n",
        "      nn.LeakyReLU(0.01),\n",
        "      nn.ConvTranspose1d( 32,  2, 400, 50, padding=200),\n",
        "    ]\n",
        "    self.main = nn.Sequential(*layers)\n",
        "\n",
        "  def forward(self, x, c):\n",
        "    # print(x.shape, c.shape)\n",
        "    c = c.view(c.size(0), c.size(1), 1) \n",
        "    c = c.repeat(1, 1, x.size(2)) \n",
        "    x = torch.cat([x, c], dim=1) \n",
        "    return self.main(x)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-c41722eY3J"
      },
      "source": [
        "G = Generator()\n",
        "D = Discriminator()\n",
        "C = Classifier()\n",
        "C_optim = torch.optim.Adam(C.parameters(), lr=0.001)\n",
        "G_optim = torch.optim.Adam(G.parameters(), lr=0.001)\n",
        "D_optim = torch.optim.Adam(D.parameters(), lr=0.001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-F5Mqj-xWgr"
      },
      "source": [
        "model = torch.load(os.path.join(MODEL_SAVE_PATH, \"stargan_spectrograms.pt\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eH7IAI6SxciP",
        "outputId": "1076127d-1b85-4db8-abf9-667f988ce1f5"
      },
      "source": [
        "C.load_state_dict(model['C-model'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlI5kNIkfd02"
      },
      "source": [
        "def classification_loss(logit, target):\n",
        "  \"\"\"Compute binary or softmax cross entropy loss.\"\"\"\n",
        "  return F.cross_entropy(logit, target, weight=WEIGHT, size_average=False) / logit.size(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-peAMot-dKg"
      },
      "source": [
        "model_path = os.path.join(MODEL_SAVE_PATH, MODEL_FILENAME)\n",
        "l = glob.glob(model_path)\n",
        "EPOCH = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9HIQr3Y-fpJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4df682c2-daad-42b5-be90-45e3ad007a04"
      },
      "source": [
        "if len(l) != 0:\n",
        "  checkpoints = torch.load(model_path)\n",
        "  C.load_state_dict(checkpoints['C-model'])\n",
        "  G.load_state_dict(checkpoints['G-model'])\n",
        "  D.load_state_dict(checkpoints['D-model'])\n",
        "  EPOCH = checkpoints['epoch']\n",
        "  print(\"Model loaded\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPjPLutETqIc",
        "outputId": "00c63c12-31d1-41f0-8b5e-3c0d9765029f"
      },
      "source": [
        "print(EPOCH)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rr2C0CZmf0BK"
      },
      "source": [
        "def train(batch_size=4, lambda_gp=10, lambda_cls=1, lambda_recon=10):\n",
        "  cudnn.benchmark = True\n",
        "\n",
        "  C.to(device)\n",
        "  G.to(device)\n",
        "  D.to(device)\n",
        "\n",
        "  clipping_value = 1\n",
        "  dataloader = DataLoader(MyIterableDataset(batch_size=batch_size), num_workers=1)\n",
        "  file_count = 0\n",
        "  gen_count = 0\n",
        "  save_count = 1\n",
        "  count = EPOCH\n",
        "  data_iter = iter(dataloader)\n",
        "\n",
        "  d_loss_real, d_loss_fake = 0, 0\n",
        "  g_loss_fake, g_loss_cls, g_loss_recon = 0, 0, 0\n",
        "  mode_flag = False\n",
        "\n",
        "  # spec_xform = torchaudio.transforms.Spectrogram().to(device)\n",
        "  # normalize = torchvision.transforms.Normalize(0,1).to(device)\n",
        "\n",
        "  while True:\n",
        "    if save_count == 0:\n",
        "      print(\"Saving model\")\n",
        "      torch.save({\n",
        "          'epoch': count,\n",
        "          'C-model': C.state_dict(),\n",
        "          'G-model': G.state_dict(),\n",
        "          'D-model': D.state_dict()\n",
        "          # 'C-optim': C_optim.state_dict(),\n",
        "      }, model_path)\n",
        "    try:\n",
        "      x_real, label_org, label_trg, spec = next(data_iter)\n",
        "    except StopIteration:\n",
        "      count += 1\n",
        "      file_count = 0\n",
        "      data_iter = iter(dataloader)\n",
        "      x_real, label_org, label_trg, spec = next(data_iter)\n",
        "\n",
        "    x_real = x_real.squeeze(0)\n",
        "    label_org = label_org.squeeze(0)\n",
        "    label_trg = label_trg.squeeze(0)\n",
        "    spec = spec.squeeze(0)\n",
        "    c_org = label2onehot(label_org, 5)\n",
        "    c_trg = label2onehot(label_trg, 5)\n",
        "\n",
        "    x_real = x_real.to(device)\n",
        "    spec = spec.to(device)\n",
        "    label_org = label_org.to(device)\n",
        "    label_trg = label_trg.to(device)\n",
        "    c_org = c_org.to(device)\n",
        "    c_trg = c_trg.to(device)\n",
        "\n",
        "    if mode_flag:\n",
        "      #### TRAINING THE DISCRIMINATOR\n",
        "      ## Real data points\n",
        "      out_src = D(spec)\n",
        "      d_loss_real = - torch.mean(out_src)\n",
        "      # Classifier is already trained, uncomment later\n",
        "      # out_cls = C(x_real)\n",
        "      # d_loss_cls  = classification_loss(out_cls, label_org)\n",
        "\n",
        "      ## Generated data points\n",
        "      with torch.no_grad():\n",
        "        x_fake = G(x_real, c_trg)\n",
        "        temp = spec_xform(denormalize(x_fake, ))\n",
        "        temp = normalize(temp)\n",
        "      out_src = D(temp)\n",
        "      d_loss_fake = torch.mean(out_src)\n",
        "\n",
        "      ## Gradient Penalty\n",
        "      alpha = torch.rand(x_real.size(0), 1, 1, device=device)\n",
        "      x_hat = (alpha * x_real.data + (1 - alpha) * x_fake.data).requires_grad_(True)\n",
        "      x_hat = spec_xform(x_hat)\n",
        "      x_hat = normalize(x_hat)\n",
        "      out_src = D(x_hat)\n",
        "      d_loss_gp = gradient_penalty(out_src, x_hat)\n",
        "\n",
        "      d_loss = d_loss_real + d_loss_fake + lambda_gp * d_loss_gp\n",
        "      # c_loss = lambda_cls * d_loss_cls\n",
        "\n",
        "      D_optim.zero_grad()\n",
        "      C_optim.zero_grad()\n",
        "\n",
        "      d_loss.backward()\n",
        "      torch.nn.utils.clip_grad_norm_(D.parameters(), clipping_value)\n",
        "      D_optim.step()\n",
        "\n",
        "      tag = \"D-step\"\n",
        "      mode_flag = (d_loss_fake >= 0)\n",
        "      # mode_flag = (gen_count < 10)\n",
        "      # c_loss.backward()\n",
        "      # C_optim.step()\n",
        "\n",
        "    else:\n",
        "      #### TRAINING THE GENERATOR\n",
        "      ## Fooling the Discriminator loss\n",
        "      x_fake = G(x_real, c_trg)\n",
        "      # d_in = spec_xform(x_fake)\n",
        "      # d_in = normalize(d_in)\n",
        "      # out_src = D(d_in)\n",
        "      # out_cls = C(d_in)\n",
        "      # g_loss_fake = - torch.mean(out_src)\n",
        "      # g_loss_cls = classification_loss(out_cls, label_trg)\n",
        "\n",
        "      ## Reconstruction loss\n",
        "      x_recon = G(x_fake, c_org)\n",
        "      g_loss_recon = torch.sum(torch.abs(x_real - x_recon)) / batch_size\n",
        "\n",
        "      # g_loss = g_loss_recon * lambda_recon + g_loss_fake + lambda_cls * g_loss_cls\n",
        "      g_loss = g_loss_recon * lambda_recon\n",
        "\n",
        "      G_optim.zero_grad()\n",
        "      D_optim.zero_grad()\n",
        "      C_optim.zero_grad()\n",
        "\n",
        "      g_loss.backward()\n",
        "      # torch.nn.utils.clip_grad_norm_(G.parameters(), clipping_value)\n",
        "      G_optim.step()\n",
        "\n",
        "      tag = \"G-step\"\n",
        "      mode_flag = (g_loss < 0)\n",
        "      # mode_flag = (gen_count < 10)\n",
        "\n",
        "    print(f\"{tag}  \" + \n",
        "          f\"D_loss_real: {d_loss_real:.4f}, \" +\n",
        "          f\"D_loss_fake: {d_loss_fake:.4f}, \" + \n",
        "          f\"G_loss_fake: {g_loss_fake:.4f}, \" +\n",
        "          f\"G_loss_cls:  {g_loss_cls:.4f},  \" +\n",
        "          f\"G_loss_recon: {g_loss_recon:.4f}\")\n",
        "\n",
        "    file_count += batch_size\n",
        "    gen_count = (gen_count + 1) % 20\n",
        "    save_count = (save_count + 1) % 20\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYjgYjBU0-yM"
      },
      "source": [
        "## How to interpret the loss\n",
        "\n",
        "```D_loss_real``` $ << 0$ (Ideally)\n",
        "\n",
        "```D_loss_fake``` $ << 0$ (Ideally)\n",
        "\n",
        "```G_loss_fake``` $ << 0$ (Ideally)\n",
        "\n",
        "```G_loss_recon``` Must be small\n",
        "\n",
        "```G_loss_cls``` Must be small"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bdyFIcEUGTz",
        "outputId": "af2aa628-a81d-4027-fc22-e1772d53e867"
      },
      "source": [
        "train(batch_size=64, lambda_cls=10, lambda_recon=0.1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "G-step  D_loss_real: 0.0000, D_loss_fake: 0.0000, G_loss_fake: 0.0000, G_loss_cls:  0.0000,  G_loss_recon: 44205.3203\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f790ace2e60>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1324, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1316, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f790ace2e60>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1324, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1316, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f790ace2e60>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1324, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1316, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "G-step  D_loss_real: 0.0000, D_loss_fake: 0.0000, G_loss_fake: 0.0000, G_loss_cls:  0.0000,  G_loss_recon: 35041.8516\n",
            "G-step  D_loss_real: 0.0000, D_loss_fake: 0.0000, G_loss_fake: 0.0000, G_loss_cls:  0.0000,  G_loss_recon: 37419.9219\n",
            "G-step  D_loss_real: 0.0000, D_loss_fake: 0.0000, G_loss_fake: 0.0000, G_loss_cls:  0.0000,  G_loss_recon: 37034.9062\n",
            "G-step  D_loss_real: 0.0000, D_loss_fake: 0.0000, G_loss_fake: 0.0000, G_loss_cls:  0.0000,  G_loss_recon: 41765.1328\n",
            "G-step  D_loss_real: 0.0000, D_loss_fake: 0.0000, G_loss_fake: 0.0000, G_loss_cls:  0.0000,  G_loss_recon: 35421.6797\n",
            "G-step  D_loss_real: 0.0000, D_loss_fake: 0.0000, G_loss_fake: 0.0000, G_loss_cls:  0.0000,  G_loss_recon: 38014.3711\n",
            "G-step  D_loss_real: 0.0000, D_loss_fake: 0.0000, G_loss_fake: 0.0000, G_loss_cls:  0.0000,  G_loss_recon: 35879.1055\n",
            "G-step  D_loss_real: 0.0000, D_loss_fake: 0.0000, G_loss_fake: 0.0000, G_loss_cls:  0.0000,  G_loss_recon: 47717.0078\n",
            "G-step  D_loss_real: 0.0000, D_loss_fake: 0.0000, G_loss_fake: 0.0000, G_loss_cls:  0.0000,  G_loss_recon: 36090.2734\n",
            "G-step  D_loss_real: 0.0000, D_loss_fake: 0.0000, G_loss_fake: 0.0000, G_loss_cls:  0.0000,  G_loss_recon: 87248.8984\n",
            "G-step  D_loss_real: 0.0000, D_loss_fake: 0.0000, G_loss_fake: 0.0000, G_loss_cls:  0.0000,  G_loss_recon: 37195.1328\n",
            "G-step  D_loss_real: 0.0000, D_loss_fake: 0.0000, G_loss_fake: 0.0000, G_loss_cls:  0.0000,  G_loss_recon: 30118.1680\n",
            "G-step  D_loss_real: 0.0000, D_loss_fake: 0.0000, G_loss_fake: 0.0000, G_loss_cls:  0.0000,  G_loss_recon: 32738.5430\n",
            "G-step  D_loss_real: 0.0000, D_loss_fake: 0.0000, G_loss_fake: 0.0000, G_loss_cls:  0.0000,  G_loss_recon: 35529.0312\n",
            "G-step  D_loss_real: 0.0000, D_loss_fake: 0.0000, G_loss_fake: 0.0000, G_loss_cls:  0.0000,  G_loss_recon: 36095.6953\n",
            "G-step  D_loss_real: 0.0000, D_loss_fake: 0.0000, G_loss_fake: 0.0000, G_loss_cls:  0.0000,  G_loss_recon: 39612.1914\n",
            "G-step  D_loss_real: 0.0000, D_loss_fake: 0.0000, G_loss_fake: 0.0000, G_loss_cls:  0.0000,  G_loss_recon: 36848.4023\n",
            "G-step  D_loss_real: 0.0000, D_loss_fake: 0.0000, G_loss_fake: 0.0000, G_loss_cls:  0.0000,  G_loss_recon: 32841.4453\n",
            "Saving model\n",
            "G-step  D_loss_real: 0.0000, D_loss_fake: 0.0000, G_loss_fake: 0.0000, G_loss_cls:  0.0000,  G_loss_recon: 35117.8125\n",
            "G-step  D_loss_real: 0.0000, D_loss_fake: 0.0000, G_loss_fake: 0.0000, G_loss_cls:  0.0000,  G_loss_recon: 40574.5898\n",
            "G-step  D_loss_real: 0.0000, D_loss_fake: 0.0000, G_loss_fake: 0.0000, G_loss_cls:  0.0000,  G_loss_recon: 39201.3633\n",
            "G-step  D_loss_real: 0.0000, D_loss_fake: 0.0000, G_loss_fake: 0.0000, G_loss_cls:  0.0000,  G_loss_recon: 39024.3438\n",
            "G-step  D_loss_real: 0.0000, D_loss_fake: 0.0000, G_loss_fake: 0.0000, G_loss_cls:  0.0000,  G_loss_recon: 34767.2305\n",
            "G-step  D_loss_real: 0.0000, D_loss_fake: 0.0000, G_loss_fake: 0.0000, G_loss_cls:  0.0000,  G_loss_recon: 41254.4727\n",
            "G-step  D_loss_real: 0.0000, D_loss_fake: 0.0000, G_loss_fake: 0.0000, G_loss_cls:  0.0000,  G_loss_recon: 40651.4062\n",
            "G-step  D_loss_real: 0.0000, D_loss_fake: 0.0000, G_loss_fake: 0.0000, G_loss_cls:  0.0000,  G_loss_recon: 34698.3984\n",
            "G-step  D_loss_real: 0.0000, D_loss_fake: 0.0000, G_loss_fake: 0.0000, G_loss_cls:  0.0000,  G_loss_recon: 36254.7383\n",
            "G-step  D_loss_real: 0.0000, D_loss_fake: 0.0000, G_loss_fake: 0.0000, G_loss_cls:  0.0000,  G_loss_recon: 45156.0156\n",
            "G-step  D_loss_real: 0.0000, D_loss_fake: 0.0000, G_loss_fake: 0.0000, G_loss_cls:  0.0000,  G_loss_recon: 35728.2656\n",
            "G-step  D_loss_real: 0.0000, D_loss_fake: 0.0000, G_loss_fake: 0.0000, G_loss_cls:  0.0000,  G_loss_recon: 32041.3066\n",
            "G-step  D_loss_real: 0.0000, D_loss_fake: 0.0000, G_loss_fake: 0.0000, G_loss_cls:  0.0000,  G_loss_recon: 37270.3828\n",
            "G-step  D_loss_real: 0.0000, D_loss_fake: 0.0000, G_loss_fake: 0.0000, G_loss_cls:  0.0000,  G_loss_recon: 34641.7500\n",
            "G-step  D_loss_real: 0.0000, D_loss_fake: 0.0000, G_loss_fake: 0.0000, G_loss_cls:  0.0000,  G_loss_recon: 39557.6875\n",
            "G-step  D_loss_real: 0.0000, D_loss_fake: 0.0000, G_loss_fake: 0.0000, G_loss_cls:  0.0000,  G_loss_recon: 43994.5977\n",
            "G-step  D_loss_real: 0.0000, D_loss_fake: 0.0000, G_loss_fake: 0.0000, G_loss_cls:  0.0000,  G_loss_recon: 39626.8867\n",
            "G-step  D_loss_real: 0.0000, D_loss_fake: 0.0000, G_loss_fake: 0.0000, G_loss_cls:  0.0000,  G_loss_recon: 37377.8750\n",
            "G-step  D_loss_real: 0.0000, D_loss_fake: 0.0000, G_loss_fake: 0.0000, G_loss_cls:  0.0000,  G_loss_recon: 37180.9961\n",
            "G-step  D_loss_real: 0.0000, D_loss_fake: 0.0000, G_loss_fake: 0.0000, G_loss_cls:  0.0000,  G_loss_recon: 65286.5156\n",
            "Saving model\n",
            "G-step  D_loss_real: 0.0000, D_loss_fake: 0.0000, G_loss_fake: 0.0000, G_loss_cls:  0.0000,  G_loss_recon: 37620.3672\n",
            "G-step  D_loss_real: 0.0000, D_loss_fake: 0.0000, G_loss_fake: 0.0000, G_loss_cls:  0.0000,  G_loss_recon: 36151.1562\n",
            "G-step  D_loss_real: 0.0000, D_loss_fake: 0.0000, G_loss_fake: 0.0000, G_loss_cls:  0.0000,  G_loss_recon: 41835.6914\n",
            "G-step  D_loss_real: 0.0000, D_loss_fake: 0.0000, G_loss_fake: 0.0000, G_loss_cls:  0.0000,  G_loss_recon: 38098.4844\n",
            "G-step  D_loss_real: 0.0000, D_loss_fake: 0.0000, G_loss_fake: 0.0000, G_loss_cls:  0.0000,  G_loss_recon: 36269.5391\n",
            "G-step  D_loss_real: 0.0000, D_loss_fake: 0.0000, G_loss_fake: 0.0000, G_loss_cls:  0.0000,  G_loss_recon: 37329.7422\n",
            "G-step  D_loss_real: 0.0000, D_loss_fake: 0.0000, G_loss_fake: 0.0000, G_loss_cls:  0.0000,  G_loss_recon: 34705.7227\n",
            "G-step  D_loss_real: 0.0000, D_loss_fake: 0.0000, G_loss_fake: 0.0000, G_loss_cls:  0.0000,  G_loss_recon: 34961.6914\n",
            "G-step  D_loss_real: 0.0000, D_loss_fake: 0.0000, G_loss_fake: 0.0000, G_loss_cls:  0.0000,  G_loss_recon: 35793.1719\n",
            "G-step  D_loss_real: 0.0000, D_loss_fake: 0.0000, G_loss_fake: 0.0000, G_loss_cls:  0.0000,  G_loss_recon: 32188.1797\n",
            "G-step  D_loss_real: 0.0000, D_loss_fake: 0.0000, G_loss_fake: 0.0000, G_loss_cls:  0.0000,  G_loss_recon: 39374.3281\n",
            "G-step  D_loss_real: 0.0000, D_loss_fake: 0.0000, G_loss_fake: 0.0000, G_loss_cls:  0.0000,  G_loss_recon: 37341.1992\n",
            "G-step  D_loss_real: 0.0000, D_loss_fake: 0.0000, G_loss_fake: 0.0000, G_loss_cls:  0.0000,  G_loss_recon: 34927.7773\n",
            "G-step  D_loss_real: 0.0000, D_loss_fake: 0.0000, G_loss_fake: 0.0000, G_loss_cls:  0.0000,  G_loss_recon: 30629.5039\n",
            "G-step  D_loss_real: 0.0000, D_loss_fake: 0.0000, G_loss_fake: 0.0000, G_loss_cls:  0.0000,  G_loss_recon: 40756.4922\n",
            "G-step  D_loss_real: 0.0000, D_loss_fake: 0.0000, G_loss_fake: 0.0000, G_loss_cls:  0.0000,  G_loss_recon: 40874.4258\n",
            "G-step  D_loss_real: 0.0000, D_loss_fake: 0.0000, G_loss_fake: 0.0000, G_loss_cls:  0.0000,  G_loss_recon: 36464.9766\n",
            "G-step  D_loss_real: 0.0000, D_loss_fake: 0.0000, G_loss_fake: 0.0000, G_loss_cls:  0.0000,  G_loss_recon: 37030.0352\n",
            "G-step  D_loss_real: 0.0000, D_loss_fake: 0.0000, G_loss_fake: 0.0000, G_loss_cls:  0.0000,  G_loss_recon: 38111.7109\n",
            "G-step  D_loss_real: 0.0000, D_loss_fake: 0.0000, G_loss_fake: 0.0000, G_loss_cls:  0.0000,  G_loss_recon: 34473.2031\n",
            "Saving model\n",
            "G-step  D_loss_real: 0.0000, D_loss_fake: 0.0000, G_loss_fake: 0.0000, G_loss_cls:  0.0000,  G_loss_recon: 39834.9922\n",
            "G-step  D_loss_real: 0.0000, D_loss_fake: 0.0000, G_loss_fake: 0.0000, G_loss_cls:  0.0000,  G_loss_recon: 35604.2969\n",
            "G-step  D_loss_real: 0.0000, D_loss_fake: 0.0000, G_loss_fake: 0.0000, G_loss_cls:  0.0000,  G_loss_recon: 38443.7734\n",
            "G-step  D_loss_real: 0.0000, D_loss_fake: 0.0000, G_loss_fake: 0.0000, G_loss_cls:  0.0000,  G_loss_recon: 32560.3320\n",
            "G-step  D_loss_real: 0.0000, D_loss_fake: 0.0000, G_loss_fake: 0.0000, G_loss_cls:  0.0000,  G_loss_recon: 39742.5469\n",
            "G-step  D_loss_real: 0.0000, D_loss_fake: 0.0000, G_loss_fake: 0.0000, G_loss_cls:  0.0000,  G_loss_recon: 38776.8906\n",
            "G-step  D_loss_real: 0.0000, D_loss_fake: 0.0000, G_loss_fake: 0.0000, G_loss_cls:  0.0000,  G_loss_recon: 32850.7656\n",
            "G-step  D_loss_real: 0.0000, D_loss_fake: 0.0000, G_loss_fake: 0.0000, G_loss_cls:  0.0000,  G_loss_recon: 37257.6797\n",
            "G-step  D_loss_real: 0.0000, D_loss_fake: 0.0000, G_loss_fake: 0.0000, G_loss_cls:  0.0000,  G_loss_recon: 38429.2734\n",
            "G-step  D_loss_real: 0.0000, D_loss_fake: 0.0000, G_loss_fake: 0.0000, G_loss_cls:  0.0000,  G_loss_recon: 47319.0586\n",
            "G-step  D_loss_real: 0.0000, D_loss_fake: 0.0000, G_loss_fake: 0.0000, G_loss_cls:  0.0000,  G_loss_recon: 40131.9453\n",
            "G-step  D_loss_real: 0.0000, D_loss_fake: 0.0000, G_loss_fake: 0.0000, G_loss_cls:  0.0000,  G_loss_recon: 36323.7891\n",
            "G-step  D_loss_real: 0.0000, D_loss_fake: 0.0000, G_loss_fake: 0.0000, G_loss_cls:  0.0000,  G_loss_recon: 33398.3320\n",
            "G-step  D_loss_real: 0.0000, D_loss_fake: 0.0000, G_loss_fake: 0.0000, G_loss_cls:  0.0000,  G_loss_recon: 43039.8633\n",
            "G-step  D_loss_real: 0.0000, D_loss_fake: 0.0000, G_loss_fake: 0.0000, G_loss_cls:  0.0000,  G_loss_recon: 41189.1406\n",
            "G-step  D_loss_real: 0.0000, D_loss_fake: 0.0000, G_loss_fake: 0.0000, G_loss_cls:  0.0000,  G_loss_recon: 43946.6797\n",
            "G-step  D_loss_real: 0.0000, D_loss_fake: 0.0000, G_loss_fake: 0.0000, G_loss_cls:  0.0000,  G_loss_recon: 36641.6953\n",
            "G-step  D_loss_real: 0.0000, D_loss_fake: 0.0000, G_loss_fake: 0.0000, G_loss_cls:  0.0000,  G_loss_recon: 37190.1562\n",
            "G-step  D_loss_real: 0.0000, D_loss_fake: 0.0000, G_loss_fake: 0.0000, G_loss_cls:  0.0000,  G_loss_recon: 42252.3984\n",
            "G-step  D_loss_real: 0.0000, D_loss_fake: 0.0000, G_loss_fake: 0.0000, G_loss_cls:  0.0000,  G_loss_recon: 37420.5078\n",
            "Saving model\n",
            "G-step  D_loss_real: 0.0000, D_loss_fake: 0.0000, G_loss_fake: 0.0000, G_loss_cls:  0.0000,  G_loss_recon: 39966.4922\n",
            "G-step  D_loss_real: 0.0000, D_loss_fake: 0.0000, G_loss_fake: 0.0000, G_loss_cls:  0.0000,  G_loss_recon: 39336.0938\n",
            "G-step  D_loss_real: 0.0000, D_loss_fake: 0.0000, G_loss_fake: 0.0000, G_loss_cls:  0.0000,  G_loss_recon: 33239.9727\n",
            "G-step  D_loss_real: 0.0000, D_loss_fake: 0.0000, G_loss_fake: 0.0000, G_loss_cls:  0.0000,  G_loss_recon: 37559.3516\n",
            "G-step  D_loss_real: 0.0000, D_loss_fake: 0.0000, G_loss_fake: 0.0000, G_loss_cls:  0.0000,  G_loss_recon: 37651.9531\n",
            "G-step  D_loss_real: 0.0000, D_loss_fake: 0.0000, G_loss_fake: 0.0000, G_loss_cls:  0.0000,  G_loss_recon: 35893.4844\n",
            "G-step  D_loss_real: 0.0000, D_loss_fake: 0.0000, G_loss_fake: 0.0000, G_loss_cls:  0.0000,  G_loss_recon: 42004.5039\n",
            "G-step  D_loss_real: 0.0000, D_loss_fake: 0.0000, G_loss_fake: 0.0000, G_loss_cls:  0.0000,  G_loss_recon: 42901.4141\n",
            "G-step  D_loss_real: 0.0000, D_loss_fake: 0.0000, G_loss_fake: 0.0000, G_loss_cls:  0.0000,  G_loss_recon: 33813.1562\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}