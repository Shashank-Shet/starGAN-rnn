{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "StarGAN_Spectrogram_Pyramid.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rPo7c63klQ4",
        "outputId": "6a60885d-ae8b-4bf6-e0a2-093ca5ed91ba"
      },
      "source": [
        "!pip install torchaudio"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchaudio\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/aa/55/01ad9244bcd595e39cea5ce30726a7fe02fd963d07daeb136bfe7e23f0a5/torchaudio-0.8.1-cp37-cp37m-manylinux1_x86_64.whl (1.9MB)\n",
            "\r\u001b[K     |▏                               | 10kB 24.2MB/s eta 0:00:01\r\u001b[K     |▍                               | 20kB 30.2MB/s eta 0:00:01\r\u001b[K     |▌                               | 30kB 20.6MB/s eta 0:00:01\r\u001b[K     |▊                               | 40kB 15.7MB/s eta 0:00:01\r\u001b[K     |▉                               | 51kB 8.3MB/s eta 0:00:01\r\u001b[K     |█                               | 61kB 8.6MB/s eta 0:00:01\r\u001b[K     |█▏                              | 71kB 8.7MB/s eta 0:00:01\r\u001b[K     |█▍                              | 81kB 9.7MB/s eta 0:00:01\r\u001b[K     |█▌                              | 92kB 10.0MB/s eta 0:00:01\r\u001b[K     |█▊                              | 102kB 8.0MB/s eta 0:00:01\r\u001b[K     |█▉                              | 112kB 8.0MB/s eta 0:00:01\r\u001b[K     |██                              | 122kB 8.0MB/s eta 0:00:01\r\u001b[K     |██▏                             | 133kB 8.0MB/s eta 0:00:01\r\u001b[K     |██▍                             | 143kB 8.0MB/s eta 0:00:01\r\u001b[K     |██▌                             | 153kB 8.0MB/s eta 0:00:01\r\u001b[K     |██▊                             | 163kB 8.0MB/s eta 0:00:01\r\u001b[K     |██▉                             | 174kB 8.0MB/s eta 0:00:01\r\u001b[K     |███                             | 184kB 8.0MB/s eta 0:00:01\r\u001b[K     |███▏                            | 194kB 8.0MB/s eta 0:00:01\r\u001b[K     |███▍                            | 204kB 8.0MB/s eta 0:00:01\r\u001b[K     |███▌                            | 215kB 8.0MB/s eta 0:00:01\r\u001b[K     |███▊                            | 225kB 8.0MB/s eta 0:00:01\r\u001b[K     |███▉                            | 235kB 8.0MB/s eta 0:00:01\r\u001b[K     |████                            | 245kB 8.0MB/s eta 0:00:01\r\u001b[K     |████▏                           | 256kB 8.0MB/s eta 0:00:01\r\u001b[K     |████▍                           | 266kB 8.0MB/s eta 0:00:01\r\u001b[K     |████▌                           | 276kB 8.0MB/s eta 0:00:01\r\u001b[K     |████▊                           | 286kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████                           | 296kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████                           | 307kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 317kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 327kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 337kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 348kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████                          | 358kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████                          | 368kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 378kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 389kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 399kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 409kB 8.0MB/s eta 0:00:01\r\u001b[K     |███████                         | 419kB 8.0MB/s eta 0:00:01\r\u001b[K     |███████                         | 430kB 8.0MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 440kB 8.0MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 450kB 8.0MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 460kB 8.0MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 471kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████                        | 481kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████                        | 491kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 501kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 512kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 522kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 532kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████                       | 542kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████                       | 552kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 563kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 573kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 583kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 593kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████                      | 604kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 614kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 624kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 634kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 645kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 655kB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████                     | 665kB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 675kB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 686kB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 696kB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 706kB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 716kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████                    | 727kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 737kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 747kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 757kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 768kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 778kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 788kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 798kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 808kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 819kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 829kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 839kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 849kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 860kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 870kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 880kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 890kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 901kB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 911kB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 921kB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 931kB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 942kB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 952kB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 962kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████████                | 972kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 983kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 993kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 1.0MB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 1.0MB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 1.0MB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 1.0MB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 1.0MB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 1.1MB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 1.1MB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 1.1MB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 1.1MB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 1.1MB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 1.1MB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 1.1MB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 1.1MB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 1.1MB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.1MB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.2MB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 1.2MB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 1.2MB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 1.2MB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 1.2MB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.2MB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.2MB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 1.2MB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 1.2MB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 1.2MB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 1.3MB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.3MB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.3MB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 1.3MB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 1.3MB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 1.3MB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 1.3MB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.3MB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.3MB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 1.4MB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 1.4MB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 1.4MB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 1.4MB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.4MB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.4MB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 1.4MB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 1.4MB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 1.4MB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 1.4MB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.5MB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 1.5MB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 1.5MB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.5MB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 1.5MB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 1.5MB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.5MB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.5MB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 1.5MB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.5MB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 1.6MB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 1.6MB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.6MB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.6MB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 1.6MB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.6MB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.6MB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 1.6MB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.6MB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.6MB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.7MB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.7MB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 1.7MB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.7MB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.7MB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 1.7MB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.7MB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 1.7MB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 1.7MB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.8MB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.8MB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.8MB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.8MB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.8MB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.8MB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.8MB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.8MB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 1.8MB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 1.8MB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.9MB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.9MB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.9MB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.9MB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.9MB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.9MB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.9MB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.9MB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.9MB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.9MB 8.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch==1.8.1 in /usr/local/lib/python3.7/dist-packages (from torchaudio) (1.8.1+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1->torchaudio) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1->torchaudio) (3.7.4.3)\n",
            "Installing collected packages: torchaudio\n",
            "Successfully installed torchaudio-0.8.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fljm8mupduwP"
      },
      "source": [
        "import torchaudio\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import IterableDataset, DataLoader\n",
        "from torch.backends import cudnn\n",
        "import numpy as np\n",
        "import glob\n",
        "import os\n",
        "from sklearn.metrics import confusion_matrix\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I75OU-XZkq1P",
        "outputId": "c6c43333-568a-469d-a833-1682e1b97a78"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('./drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at ./drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lNs4Dscxyw0"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0hsUsw7iFMz"
      },
      "source": [
        "SPEC_DATASET_PATH = \"./drive/MyDrive/cs753 dataset/spectrograms/\"\n",
        "AUDIO_DATASET_PATH = \"./drive/MyDrive/cs753 dataset/audio/\"\n",
        "MODEL_SAVE_PATH = \"./drive/MyDrive/cs753 dataset/\"\n",
        "MODEL_FILENAME = \"stargan_spectrograms2.pt\"\n",
        "\n",
        "INSTRUMENTS = [\n",
        "    \"Bansuri\",\n",
        "    \"Shehnai\",\n",
        "    \"Santoor\",\n",
        "    \"Sarod\",\n",
        "    \"Violin\"\n",
        "]\n",
        "\n",
        "INSTRUMENT_LABELS = {\n",
        "    \"Bansuri\" : 0,\n",
        "    \"Shehnai\" : 1,\n",
        "    \"Santoor\" : 2,\n",
        "    \"Sarod\"   : 3,\n",
        "    \"Violin\"  : 4\n",
        "}\n",
        "\n",
        "WEIGHT = np.array([\n",
        "    891,\n",
        "    1664,\n",
        "    1122,\n",
        "    765,\n",
        "    1193\n",
        "])\n",
        "WEIGHT = torch.tensor((WEIGHT / (WEIGHT.sum())) ** -1)\n",
        "WEIGHT = WEIGHT.float().to(device)\n",
        "\n",
        "spec_files_path = os.path.join(SPEC_DATASET_PATH, \"*.pt\")\n",
        "audio_files_path = os.path.join(AUDIO_DATASET_PATH, \"*.pt\")\n",
        "SPEC_FILES = sorted(glob.glob(spec_files_path))\n",
        "AUDIO_FILES = sorted(glob.glob(audio_files_path))\n",
        "NUM_FILES = len(SPEC_FILES)\n",
        "\n",
        " \n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8u9jcGT0B00",
        "outputId": "c980b132-705b-4d37-99d8-022f63154f44"
      },
      "source": [
        "print(NUM_FILES)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5637\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbjimf6HeKyy"
      },
      "source": [
        "def normalize(data):\n",
        "  data = data.type(torch.FloatTensor).unsqueeze(0)\n",
        "  mean = data.mean(dim=2).unsqueeze(2)\n",
        "  std = data.std(dim=2).unsqueeze(2)\n",
        "  std[std == 0] = 1\n",
        "  data = (data - mean) / std\n",
        "  return data, mean, std"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5H0lqA0_YAbs"
      },
      "source": [
        "def label2onehot(labels, dim):\n",
        "  \"\"\"Convert label indices to one-hot vectors.\"\"\"\n",
        "  batch_size = labels.size(0)\n",
        "  out = torch.zeros(batch_size, dim)\n",
        "  out[np.arange(batch_size), labels.long()] = 1\n",
        "  return out\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97ujdlVjlqw6"
      },
      "source": [
        "def gradient_penalty(y, x):\n",
        "  \"\"\"Compute gradient penalty: (L2_norm(dy/dx) - 1)**2.\"\"\"\n",
        "  weight = torch.ones(y.size(), device=device)\n",
        "  dydx = torch.autograd.grad(outputs=y,\n",
        "                              inputs=x,\n",
        "                              grad_outputs=weight,\n",
        "                              retain_graph=True,\n",
        "                              create_graph=True,\n",
        "                              only_inputs=True)[0]\n",
        "\n",
        "  dydx = dydx.view(dydx.size(0), -1)\n",
        "  dydx_l2norm = torch.sqrt(torch.sum(dydx**2, dim=1))\n",
        "  return torch.mean((dydx_l2norm-1)**2)\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPoaAcId1loM"
      },
      "source": [
        "class DataSource:\n",
        "\n",
        "  def __init__(self, batch_size=4):\n",
        "    self.order = np.random.permutation(NUM_FILES)\n",
        "    self.batch_size = batch_size\n",
        "    self.counter = 0\n",
        "\n",
        "  def __next__(self):\n",
        "    if self.counter >= NUM_FILES:\n",
        "      self.order = np.random.permutation(NUM_FILES)\n",
        "      self.counter = 0\n",
        "      raise StopIteration()\n",
        "    file_indices = self.order[self.counter:self.counter+self.batch_size]\n",
        "    self.counter += self.batch_size\n",
        "    x_tensor_list = []\n",
        "    y_tensor_list = []\n",
        "    spec_tensor_list = []\n",
        "    for index in file_indices:\n",
        "      audio_filename = AUDIO_FILES[index]\n",
        "      spec_filename = SPEC_FILES[index]\n",
        "      data = torch.load(audio_filename)\n",
        "      d = torch.load(spec_filename)\n",
        "      label = d['y'] \n",
        "      spec = d['x']\n",
        "      x_tensor_list.append(data)\n",
        "      y_tensor_list.append(label)\n",
        "      spec_tensor_list.append(spec)\n",
        "    X = torch.vstack(x_tensor_list)\n",
        "    # print(y_tensor_list[0].shape)\n",
        "    y = torch.tensor(y_tensor_list)\n",
        "    s = torch.vstack(spec_tensor_list)\n",
        "    y_perm = torch.randint(0, 5, size=[y.shape[0]])\n",
        "    return X, y, y_perm, s\n",
        "\n",
        "class MyIterableDataset(IterableDataset):\n",
        "\n",
        "  def __init__(self, batch_size=4):\n",
        "    self.source = DataSource(batch_size)\n",
        "\n",
        "  def __iter__(self):\n",
        "    return self.source\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8f2ZBdSZ1cM"
      },
      "source": [
        "class Backbone(nn.Module):\n",
        "  \"\"\" Feature Extraction Network\"\"\" \n",
        "  def __init__(self): \n",
        "    super(Backbone, self).__init__() \n",
        "    layers = [] \n",
        "    layers.append(nn.Conv2d(2, 32, [5,41], [3,21])) \n",
        "    layers.append(nn.InstanceNorm2d(32)) \n",
        "    layers.append(nn.LeakyReLU(0.01)) \n",
        "    layers.append(nn.Conv2d(32, 64, 5, 3)) \n",
        "    layers.append(nn.InstanceNorm2d(64)) \n",
        "    layers.append(nn.LeakyReLU(0.01)) \n",
        "    layers.append(nn.Conv2d(64, 128, 4, 2)) \n",
        "    layers.append(nn.InstanceNorm2d(32))         \n",
        "    layers.append(nn.LeakyReLU(0.01)) \n",
        "    self.main = nn.Sequential(*layers) \n",
        "      \n",
        "  def forward(self, x): \n",
        "    return self.main(x)\n",
        "\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "  \"\"\" Classification head for the backbone \"\"\"\n",
        "  def __init__(self): \n",
        "    super(Classifier, self).__init__() \n",
        "    self.bb = Backbone() \n",
        "    self.conv = nn.Conv2d(128, 5, [9,11], 1) \n",
        "      \n",
        "  def forward(self, x): \n",
        "    x = self.bb(x) \n",
        "    x = self.conv(x) \n",
        "    y = x.view(x.shape[0], x.shape[1])\n",
        "    return y\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "  \"\"\" Discrimination head for the backbone \"\"\"\n",
        "  def __init__(self): \n",
        "    super(Discriminator, self).__init__() \n",
        "    self.bb = Backbone() \n",
        "    self.disc = nn.Conv2d(128, 1, [9,11], 1) \n",
        "      \n",
        "  def forward(self, x): \n",
        "    x = self.bb(x) \n",
        "    x = self.disc(x) \n",
        "    y = x.view(x.shape[0], x.shape[1])\n",
        "    return y\n",
        "\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "  \"\"\"Residual Block with instance normalization.\"\"\"\n",
        "  def __init__(self, dim_in, dim_out):\n",
        "    super(ResidualBlock, self).__init__()\n",
        "    self.conv1 = nn.Sequential(\n",
        "      nn.Conv1d(dim_in, dim_in, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "      nn.LeakyReLU(0.01),\n",
        "    ) \n",
        "    self.conv2 = nn.Sequential(\n",
        "      nn.Conv1d(dim_in, dim_out, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "      nn.LeakyReLU(0.01)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.conv2(x + self.conv1(x))\n",
        "\n",
        "class UpsampleLayer(nn.Module):\n",
        "  def __init__(self, dim_in, dim_out, kernel_size, stride, padding):\n",
        "    super(UpsampleLayer, self).__init__()\n",
        "    self.main = nn.Sequential(\n",
        "      nn.ConvTranspose1d(dim_in, dim_out, kernel_size, stride, padding=padding),\n",
        "      nn.LeakyReLU(0.01),\n",
        "    )\n",
        "\n",
        "  def forward(self, x_deep, x):\n",
        "    x = x + x_deep\n",
        "    return self.main(x)\n",
        "    \n",
        "\n",
        "class Generator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Generator, self).__init__()\n",
        "    self.conv1 = nn.Sequential(\n",
        "      nn.Conv1d(7, 32, 400, 50, padding=200),\n",
        "      nn.LeakyReLU(0.01),\n",
        "    )\n",
        "    self.conv2 = nn.Sequential(\n",
        "      nn.Conv1d(32, 64, 5, 2, padding=2),\n",
        "      nn.LeakyReLU(0.01),\n",
        "    )\n",
        "    self.conv3 = nn.Sequential(\n",
        "      nn.Conv1d(64, 128, 5, 2, padding=2),\n",
        "      nn.LeakyReLU(0.01),\n",
        "    )\n",
        "    self.bottleneck = nn.Sequential(\n",
        "      ResidualBlock(128, 256),\n",
        "      ResidualBlock(256, 512),\n",
        "      ResidualBlock(512, 256),\n",
        "      ResidualBlock(256, 128),        \n",
        "    )\n",
        "    self.deconv3 = nn.ConvTranspose1d( 128,  64, 5, 2, padding=2),\n",
        "    self.deconv3 = UpsampleLayer(128, 64,   5,  2,   2)\n",
        "    self.deconv2 = UpsampleLayer( 64, 32,   5,  2,   2)\n",
        "    self.deconv1 = UpsampleLayer( 32,  2, 400, 50, 200)\n",
        "\n",
        "  def forward(self, x, c):\n",
        "    c = c.view(c.size(0), c.size(1), 1) \n",
        "    c = c.repeat(1, 1, x.size(2)) \n",
        "    x = torch.cat([x, c], dim=1) \n",
        "\n",
        "    conv1   = self.conv1(x)\n",
        "    conv2   = self.conv2(conv1)\n",
        "    conv3   = self.conv3(conv2)\n",
        "    bottle  = self.bottleneck(conv3)\n",
        "    deconv3 = self.deconv3(conv3, bottle)\n",
        "    deconv2 = self.deconv2(conv2, deconv3)\n",
        "    deconv1 = self.deconv1(conv1, deconv2)\n",
        "    return deconv1"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-c41722eY3J"
      },
      "source": [
        "G = Generator()\n",
        "D = Discriminator()\n",
        "C = Classifier()\n",
        "C_optim = torch.optim.Adam(C.parameters(), lr=0.001)\n",
        "G_optim = torch.optim.Adam(G.parameters(), lr=0.001)\n",
        "D_optim = torch.optim.Adam(D.parameters(), lr=0.001)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-F5Mqj-xWgr"
      },
      "source": [
        "model = torch.load(os.path.join(MODEL_SAVE_PATH, \"stargan_spectrograms.pt\"))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eH7IAI6SxciP",
        "outputId": "1dec08c6-a01b-40c8-d9c2-feb7a8cdb1a1"
      },
      "source": [
        "C.load_state_dict(model['C-model'])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlI5kNIkfd02"
      },
      "source": [
        "def classification_loss(logit, target):\n",
        "  \"\"\"Compute binary or softmax cross entropy loss.\"\"\"\n",
        "  return F.cross_entropy(logit, target, weight=WEIGHT, size_average=False) / logit.size(0)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-peAMot-dKg"
      },
      "source": [
        "model_path = os.path.join(MODEL_SAVE_PATH, MODEL_FILENAME)\n",
        "l = glob.glob(model_path)\n",
        "EPOCH = 1"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9HIQr3Y-fpJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4306a49-30ae-4c29-d304-d4b4758e34fd"
      },
      "source": [
        "if len(l) != 0:\n",
        "  checkpoints = torch.load(model_path)\n",
        "  C.load_state_dict(checkpoints['C-model'])\n",
        "  G.load_state_dict(checkpoints['G-model'])\n",
        "  D.load_state_dict(checkpoints['D-model'])\n",
        "  EPOCH = checkpoints['epoch']\n",
        "  print(\"Model loaded\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPjPLutETqIc",
        "outputId": "00c63c12-31d1-41f0-8b5e-3c0d9765029f"
      },
      "source": [
        "print(EPOCH)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rr2C0CZmf0BK"
      },
      "source": [
        "def train(batch_size=4, lambda_gp=10, lambda_cls=1, lambda_recon=10):\n",
        "  cudnn.benchmark = True\n",
        "\n",
        "  C.to(device)\n",
        "  G.to(device)\n",
        "  D.to(device)\n",
        "\n",
        "  clipping_value = 1\n",
        "  dataloader = DataLoader(MyIterableDataset(batch_size=batch_size), num_workers=1)\n",
        "  file_count = 0\n",
        "  gen_count = 0\n",
        "  save_count = 1\n",
        "  count = EPOCH\n",
        "  data_iter = iter(dataloader)\n",
        "\n",
        "  d_loss_real, d_loss_fake = 0, 0\n",
        "  g_loss_fake, g_loss_cls, g_loss_recon = 0, 0, 0\n",
        "  mode_flag = True\n",
        "\n",
        "  spec_xform = torchaudio.transforms.Spectrogram().to(device)\n",
        "\n",
        "  while True:\n",
        "    if save_count == 0:\n",
        "      print(\"Saving model\")\n",
        "      torch.save({\n",
        "          'epoch': count,\n",
        "          'C-model': C.state_dict(),\n",
        "          'G-model': G.state_dict(),\n",
        "          'D-model': D.state_dict()\n",
        "          # 'C-optim': C_optim.state_dict(),\n",
        "      }, model_path)\n",
        "    try:\n",
        "      x_real, label_org, label_trg, spec = next(data_iter)\n",
        "    except StopIteration:\n",
        "      count += 1\n",
        "      file_count = 0\n",
        "      data_iter = iter(dataloader)\n",
        "      x_real, label_org, label_trg, spec = next(data_iter)\n",
        "\n",
        "    x_real = x_real.squeeze(0)\n",
        "    label_org = label_org.squeeze(0)\n",
        "    label_trg = label_trg.squeeze(0)\n",
        "    spec = spec.squeeze(0)\n",
        "    c_org = label2onehot(label_org, 5)\n",
        "    c_trg = label2onehot(label_trg, 5)\n",
        "\n",
        "    x_real = x_real.to(device)\n",
        "    spec = spec.to(device)\n",
        "    label_org = label_org.to(device)\n",
        "    label_trg = label_trg.to(device)\n",
        "    c_org = c_org.to(device)\n",
        "    c_trg = c_trg.to(device)\n",
        "\n",
        "    if mode_flag:\n",
        "      #### TRAINING THE DISCRIMINATOR\n",
        "      ## Real data points\n",
        "      out_src = D(spec)\n",
        "      d_loss_real = - torch.mean(out_src)\n",
        "      # Classifier is already trained, uncomment later\n",
        "      # out_cls = C(x_real)\n",
        "      # d_loss_cls  = classification_loss(out_cls, label_org)\n",
        "\n",
        "      ## Generated data points\n",
        "      with torch.no_grad():\n",
        "        x_fake = G(x_real, c_trg)\n",
        "        temp = spec_xform(x_fake)\n",
        "      out_src = D(temp)\n",
        "      d_loss_fake = torch.mean(out_src)\n",
        "\n",
        "      ## Gradient Penalty\n",
        "      alpha = torch.rand(x_real.size(0), 1, 1, device=device)\n",
        "      x_hat = (alpha * x_real.data + (1 - alpha) * x_fake.data).requires_grad_(True)\n",
        "      x_hat = spec_xform(x_hat)\n",
        "      out_src = D(x_hat)\n",
        "      d_loss_gp = gradient_penalty(out_src, x_hat)\n",
        "\n",
        "      d_loss = d_loss_real + d_loss_fake + lambda_gp * d_loss_gp\n",
        "      # c_loss = lambda_cls * d_loss_cls\n",
        "\n",
        "      D_optim.zero_grad()\n",
        "      C_optim.zero_grad()\n",
        "\n",
        "      d_loss.backward()\n",
        "      torch.nn.utils.clip_grad_norm_(D.parameters(), clipping_value)\n",
        "      D_optim.step()\n",
        "\n",
        "      tag = \"D-step\"\n",
        "      mode_flag = (d_loss_fake >= 0)\n",
        "      # c_loss.backward()\n",
        "      # C_optim.step()\n",
        "\n",
        "    else:\n",
        "      #### TRAINING THE GENERATOR\n",
        "      ## Fooling the Discriminator loss\n",
        "      x_fake = G(x_real, c_trg)\n",
        "      d_in = spec_xform(x_fake)\n",
        "      out_src = D(d_in)\n",
        "      out_cls = C(d_in)\n",
        "      g_loss_fake = - torch.mean(out_src)\n",
        "      g_loss_cls = classification_loss(out_cls, label_trg)\n",
        "\n",
        "      ## Reconstruction loss\n",
        "      x_recon = G(x_fake, c_org)\n",
        "      g_loss_recon = torch.sum(torch.abs(x_real - x_recon)) / batch_size\n",
        "\n",
        "      g_loss = g_loss_recon * lambda_recon + g_loss_fake + lambda_cls * g_loss_cls\n",
        "\n",
        "      G_optim.zero_grad()\n",
        "      D_optim.zero_grad()\n",
        "      C_optim.zero_grad()\n",
        "\n",
        "      g_loss.backward()\n",
        "      torch.nn.utils.clip_grad_norm_(G.parameters(), clipping_value)\n",
        "      G_optim.step()\n",
        "\n",
        "      tag = \"G-step\"\n",
        "      mode_flag = (g_loss < 0)\n",
        "\n",
        "    print(f\"{tag}  \" + \n",
        "          f\"D_loss_real: {d_loss_real:.4f}, \" +\n",
        "          f\"D_loss_fake: {d_loss_fake:.4f}, \" + \n",
        "          f\"G_loss_fake: {g_loss_fake:.4f}, \" +\n",
        "          f\"G_loss_cls:  {g_loss_cls:.4f},  \" +\n",
        "          f\"G_loss_recon: {g_loss_recon:.4f}\")\n",
        "\n",
        "    file_count += batch_size\n",
        "    gen_count = (gen_count + 1) % 10\n",
        "    save_count = (save_count + 1) % 20\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYjgYjBU0-yM"
      },
      "source": [
        "## How to interpret the loss\n",
        "\n",
        "```D_loss_real``` $ << 0$ (Ideally)\n",
        "\n",
        "```D_loss_fake``` $ << 0$ (Ideally)\n",
        "\n",
        "```G_loss_fake``` $ << 0$ (Ideally)\n",
        "\n",
        "```G_loss_recon``` Must be small\n",
        "\n",
        "```G_loss_cls``` Must be small"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        },
        "id": "3bdyFIcEUGTz",
        "outputId": "402d8f1a-5860-4518-8bbd-9c684853ba7f"
      },
      "source": [
        "train(batch_size=3, lambda_cls=20, lambda_recon=20)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "D-step  D_loss_real: 0.3297, D_loss_fake: -0.0666, G_loss_fake: 0.0000, G_loss_cls:  0.0000,  G_loss_recon: 0.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "G-step  D_loss_real: 0.3297, D_loss_fake: -0.0666, G_loss_fake: 0.3136, G_loss_cls:  100.2079,  G_loss_recon: 38744.9609\n",
            "G-step  D_loss_real: 0.3297, D_loss_fake: -0.0666, G_loss_fake: 0.3989, G_loss_cls:  92.8687,  G_loss_recon: 43288.5391\n",
            "G-step  D_loss_real: 0.3297, D_loss_fake: -0.0666, G_loss_fake: 0.3474, G_loss_cls:  211.5982,  G_loss_recon: 38272.5703\n",
            "G-step  D_loss_real: 0.3297, D_loss_fake: -0.0666, G_loss_fake: 0.3112, G_loss_cls:  132.2118,  G_loss_recon: 15485.2217\n",
            "G-step  D_loss_real: 0.3297, D_loss_fake: -0.0666, G_loss_fake: 0.2403, G_loss_cls:  100.4062,  G_loss_recon: 22666.3262\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-e0b8f59a5767>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_recon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-27-75c4df2a373e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(batch_size, lambda_gp, lambda_cls, lambda_recon)\u001b[0m\n\u001b[1;32m     31\u001b[0m       }, model_path)\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m       \u001b[0mx_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_org\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_trg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m       \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1182\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1183\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1146\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1148\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1149\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}