{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "StarGAN_STFT.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rPo7c63klQ4",
        "outputId": "b972eb77-d4c0-473b-bcda-fb5009bdee8a"
      },
      "source": [
        "!pip install torchaudio"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchaudio\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/aa/55/01ad9244bcd595e39cea5ce30726a7fe02fd963d07daeb136bfe7e23f0a5/torchaudio-0.8.1-cp37-cp37m-manylinux1_x86_64.whl (1.9MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9MB 11.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch==1.8.1 in /usr/local/lib/python3.7/dist-packages (from torchaudio) (1.8.1+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1->torchaudio) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1->torchaudio) (3.7.4.3)\n",
            "Installing collected packages: torchaudio\n",
            "Successfully installed torchaudio-0.8.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fljm8mupduwP"
      },
      "source": [
        "import torchaudio\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import IterableDataset, DataLoader\n",
        "from torch.backends import cudnn\n",
        "import numpy as np\n",
        "import glob\n",
        "import os\n",
        "from sklearn.metrics import confusion_matrix\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I75OU-XZkq1P",
        "outputId": "0cdf29b1-1a1e-41d1-880e-69ebaea55bb3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('./drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at ./drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lNs4Dscxyw0"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0hsUsw7iFMz"
      },
      "source": [
        "DATASET_PATH = \"./drive/MyDrive/cs753 dataset/stft/\"\n",
        "MODEL_SAVE_PATH = \"./drive/MyDrive/cs753 dataset/\"\n",
        "MODEL_FILENAME = \"stargan_stft.pt\"\n",
        "\n",
        "INSTRUMENTS = [\n",
        "    \"Bansuri\",\n",
        "    \"Shehnai\",\n",
        "    \"Santoor\",\n",
        "    \"Sarod\",\n",
        "    \"Violin\"\n",
        "]\n",
        "\n",
        "INSTRUMENT_LABELS = {\n",
        "    \"Bansuri\" : 0,\n",
        "    \"Shehnai\" : 1,\n",
        "    \"Santoor\" : 2,\n",
        "    \"Sarod\"   : 3,\n",
        "    \"Violin\"  : 4\n",
        "}\n",
        "\n",
        "WEIGHT = np.array([\n",
        "    891,\n",
        "    1664,\n",
        "    1122,\n",
        "    765,\n",
        "    1193\n",
        "])\n",
        "WEIGHT = torch.tensor((WEIGHT / (WEIGHT.sum())) ** -1)\n",
        "WEIGHT = WEIGHT.float().to(device)\n",
        "\n",
        "files_path = os.path.join(DATASET_PATH, \"*.pt\")\n",
        "FILES = sorted(glob.glob(files_path))\n",
        "NUM_FILES = len(FILES)\n",
        "\n",
        " \n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8u9jcGT0B00",
        "outputId": "83acca5d-43e2-4c5a-8d7d-233adc06120c"
      },
      "source": [
        "print(NUM_FILES)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11274\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbjimf6HeKyy"
      },
      "source": [
        "def normalize(data):\n",
        "  data = data.type(torch.FloatTensor).unsqueeze(0)\n",
        "  mean = data.mean(dim=2).unsqueeze(2)\n",
        "  std = data.std(dim=2).unsqueeze(2)\n",
        "  std[std == 0] = 1\n",
        "  data = (data - mean) / std\n",
        "  return data, mean, std"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5H0lqA0_YAbs"
      },
      "source": [
        "def label2onehot(labels, dim):\n",
        "  \"\"\"Convert label indices to one-hot vectors.\"\"\"\n",
        "  batch_size = labels.size(0)\n",
        "  out = torch.zeros(batch_size, dim)\n",
        "  out[np.arange(batch_size), labels.long()] = 1\n",
        "  return out\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97ujdlVjlqw6"
      },
      "source": [
        "def gradient_penalty(y, x):\n",
        "  \"\"\"Compute gradient penalty: (L2_norm(dy/dx) - 1)**2.\"\"\"\n",
        "  weight = torch.ones(y.size(), device=device)\n",
        "  dydx = torch.autograd.grad(outputs=y,\n",
        "                              inputs=x,\n",
        "                              grad_outputs=weight,\n",
        "                              retain_graph=True,\n",
        "                              create_graph=True,\n",
        "                              only_inputs=True)[0]\n",
        "\n",
        "  dydx = dydx.view(dydx.size(0), -1)\n",
        "  dydx_l2norm = torch.sqrt(torch.sum(dydx**2, dim=1))\n",
        "  return torch.mean((dydx_l2norm-1)**2)\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPoaAcId1loM"
      },
      "source": [
        "class DataSource:\n",
        "\n",
        "  def __init__(self, batch_size=4):\n",
        "    self.order = np.random.permutation(NUM_FILES)\n",
        "    self.batch_size = batch_size\n",
        "    self.counter = 0\n",
        "\n",
        "  def __next__(self):\n",
        "    if self.counter >= NUM_FILES:\n",
        "      self.order = np.random.permutation(NUM_FILES)\n",
        "      self.counter = 0\n",
        "      raise StopIteration()\n",
        "    file_indices = self.order[self.counter:self.counter+self.batch_size]\n",
        "    self.counter += self.batch_size\n",
        "    x_tensor_list = []\n",
        "    y_tensor_list = []\n",
        "    for index in file_indices:\n",
        "      filename = FILES[index]\n",
        "      d = torch.load(filename)\n",
        "      data  = d['x']\n",
        "      label = d['y'] \n",
        "      # data, _, _ = normalize(data.squeeze(0))\n",
        "      x_tensor_list.append(data)\n",
        "      y_tensor_list.append(label)\n",
        "    X = torch.vstack(x_tensor_list)\n",
        "    # print(y_tensor_list[0].shape)\n",
        "    y = torch.tensor(y_tensor_list)\n",
        "    y_perm = torch.randint(0, 5, size=[y.shape[0]])\n",
        "    # y_perm = (y.clone() + torch.randint(1, 5, size=[y.shape[0]])) % 5\n",
        "    return X, y, y_perm\n",
        "\n",
        "class MyIterableDataset(IterableDataset):\n",
        "\n",
        "  def __init__(self, batch_size=4):\n",
        "    self.source = DataSource(batch_size)\n",
        "\n",
        "  def __iter__(self):\n",
        "    return self.source\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8f2ZBdSZ1cM"
      },
      "source": [
        "class Backbone(nn.Module):\n",
        "  \"\"\" Feature Extraction Network\"\"\" \n",
        "  def __init__(self): \n",
        "    super(Backbone, self).__init__() \n",
        "    self.conv1 = nn.Conv3d(2, 32, [5,33,2], stride=[2, 16, 1], padding=[2,16,0])\n",
        "    self.main = nn.Sequential(\n",
        "        nn.BatchNorm2d(32),\n",
        "        nn.LeakyReLU(0.01),\n",
        "        nn.Conv2d(32, 64, 5, stride=2, padding=2),\n",
        "        nn.BatchNorm2d(64),\n",
        "        nn.LeakyReLU(0.01),\n",
        "        nn.MaxPool2d(3,3),\n",
        "        nn.Conv2d(64, 128, 5, stride=2, padding=2),\n",
        "        nn.BatchNorm2d(128),\n",
        "        nn.LeakyReLU(0.01),\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = x.squeeze(-1)\n",
        "    return self.main(x)\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "  \"\"\" Discrimination head for the backbone \"\"\"\n",
        "  def __init__(self): \n",
        "    super(Discriminator, self).__init__() \n",
        "    self.bb = Backbone() \n",
        "    self.conv = nn.Conv2d(128, 5, 9, stride=1) \n",
        "    self.disc = nn.Conv2d(128, 1, 9, stride=1) \n",
        "      \n",
        "  def forward(self, x, classify=True): \n",
        "    x = self.bb(x)\n",
        "    src = self.disc(x) \n",
        "    if classify == False:\n",
        "      return src.view(src.shape[0], src.shape[1]), None\n",
        "    cls = self.conv(x)\n",
        "    return src.view(src.shape[0], src.shape[1]), cls.view(cls.shape[0], cls.shape[1])\n",
        "\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "  \"\"\"Residual Block with instance normalization.\"\"\"\n",
        "  def __init__(self, dim_in, dim_out):\n",
        "    super(ResidualBlock, self).__init__()\n",
        "    self.main = nn.Sequential(\n",
        "      nn.Conv2d(dim_in, dim_out, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "      nn.LeakyReLU(0.01),\n",
        "      nn.Conv2d(dim_out, dim_out, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "    )\n",
        "    self.relu = nn.LeakyReLU(0.01)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.relu(x + self.main(x))\n",
        "\n",
        "\n",
        "class Generator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Generator, self).__init__()\n",
        "    self.conv1 = nn.Conv3d(7, 32, [5,33,2], stride=[2, 16, 1], padding=[2,16,0])\n",
        "    self.main = nn.Sequential(\n",
        "      nn.LeakyReLU(0.01),\n",
        "      nn.Conv2d(32, 64, 5, 2, padding=2),\n",
        "      nn.LeakyReLU(0.01),\n",
        "      nn.Conv2d(64, 128, 5, 2, padding=2),\n",
        "      nn.LeakyReLU(0.01),\n",
        "      ResidualBlock(128, 128),\n",
        "      ResidualBlock(128, 128),\n",
        "      nn.ConvTranspose2d(128, 64, 5, 2, padding=2),\n",
        "      nn.LeakyReLU(0.01),\n",
        "      nn.ConvTranspose2d( 64, 32, 5, 2, padding=2),\n",
        "      nn.LeakyReLU(0.01),\n",
        "    )\n",
        "    self.deconv1 = nn.ConvTranspose3d(32, 2, [5,33,2], stride=[2,16,1], padding=[2,16,0])\n",
        "\n",
        "  def forward(self, x, c):\n",
        "    # print(x.shape, c.shape)\n",
        "    c = c.view(c.size(0), c.size(1), 1, 1, 1)\n",
        "    c = c.repeat(1, 1, x.size(2), x.size(3), x.size(4))\n",
        "    x = torch.cat([x, c], dim=1)\n",
        "    x = self.conv1(x).squeeze(-1)\n",
        "    x = self.main(x).unsqueeze(-1)\n",
        "    x = self.deconv1(x)\n",
        "    return x\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6B-mxJRi1K0J"
      },
      "source": [
        "D = Discriminator()\n",
        "G = Generator()\n",
        "D_optim = torch.optim.Adam(D.parameters(), lr=0.001)\n",
        "G_optim = torch.optim.Adam(G.parameters(), lr=0.001)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmV0tBCh1WTm"
      },
      "source": [
        "temp = torch.randn([1,2,201,1601,2])\n",
        "with torch.no_grad():\n",
        "  r1, r2 = D(temp)\n",
        "  g1 = G(temp, torch.tensor([[1,0,0,0,0]]))"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTnMSj2G1ink",
        "outputId": "7c60faea-2028-4677-d3bf-48e4185cbeee"
      },
      "source": [
        "print(g1.shape)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 2, 201, 1601, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-F5Mqj-xWgr"
      },
      "source": [
        "model = torch.load(os.path.join(MODEL_SAVE_PATH, \"classifier_stft.pt\"))"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eH7IAI6SxciP",
        "outputId": "6cd4034c-fe3f-48c3-91bf-133163d50404"
      },
      "source": [
        "D.load_state_dict(model['C-model'], strict=False)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "_IncompatibleKeys(missing_keys=['disc.weight', 'disc.bias'], unexpected_keys=[])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlI5kNIkfd02"
      },
      "source": [
        "def classification_loss(logit, target):\n",
        "  \"\"\"Compute binary or softmax cross entropy loss.\"\"\"\n",
        "  return F.cross_entropy(logit, target, weight=WEIGHT, size_average=False) / logit.size(0)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-peAMot-dKg"
      },
      "source": [
        "model_path = os.path.join(MODEL_SAVE_PATH, MODEL_FILENAME)\n",
        "l = glob.glob(model_path)\n",
        "EPOCH = 1"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9HIQr3Y-fpJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bff868c3-1356-4cb8-9c32-5dc9db3fdc71"
      },
      "source": [
        "if len(l) != 0:\n",
        "  checkpoints = torch.load(model_path)\n",
        "  G.load_state_dict(checkpoints['G-model'])\n",
        "  D.load_state_dict(checkpoints['D-model'])\n",
        "  EPOCH = checkpoints['epoch']\n",
        "  print(\"Model loaded\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPjPLutETqIc",
        "outputId": "00c63c12-31d1-41f0-8b5e-3c0d9765029f"
      },
      "source": [
        "print(EPOCH)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rr2C0CZmf0BK"
      },
      "source": [
        "def train(batch_size=4, lambda_gp=10, lambda_cls=1, lambda_recon=10, accumulate=1):\n",
        "  cudnn.benchmark = True\n",
        "\n",
        "  G.to(device)\n",
        "  D.to(device)\n",
        "\n",
        "  clipping_value = 1\n",
        "  dataloader = DataLoader(MyIterableDataset(batch_size=batch_size), num_workers=1)\n",
        "  file_count = 0\n",
        "  gen_count = 0\n",
        "  save_count = 1\n",
        "  apply_grad = 1\n",
        "  count = EPOCH\n",
        "  data_iter = iter(dataloader)\n",
        "\n",
        "  d_loss_real, d_loss_fake, d_loss_cls = 0, 0, 0\n",
        "  g_loss_fake, g_loss_cls, g_loss_recon = 0, 0, 0\n",
        "  mode_flag = True\n",
        "\n",
        "  G_optim.zero_grad()\n",
        "  D_optim.zero_grad()\n",
        "\n",
        "  while True:\n",
        "    if save_count == 0:\n",
        "      print(\"Saving model\")\n",
        "      torch.save({\n",
        "          'epoch': count,\n",
        "          'G-model': G.state_dict(),\n",
        "          'D-model': D.state_dict()\n",
        "      }, model_path)\n",
        "    try:\n",
        "      x_real, label_org, label_trg = next(data_iter)\n",
        "    except StopIteration:\n",
        "      count += 1\n",
        "      file_count = 0\n",
        "      data_iter = iter(dataloader)\n",
        "      x_real, label_org, label_trg = next(data_iter)\n",
        "\n",
        "    x_real = x_real.squeeze(0)\n",
        "    label_org = label_org.squeeze(0)\n",
        "    label_trg = label_trg.squeeze(0)\n",
        "    c_org = label2onehot(label_org, 5)\n",
        "    c_trg = label2onehot(label_trg, 5)\n",
        "\n",
        "    x_real = x_real.to(device)\n",
        "    label_org = label_org.to(device)\n",
        "    label_trg = label_trg.to(device)\n",
        "    c_org = c_org.to(device)\n",
        "    c_trg = c_trg.to(device)\n",
        "\n",
        "    # if gen_count < 10:\n",
        "    if mode_flag:\n",
        "      #### TRAINING THE DISCRIMINATOR\n",
        "      ## Real data points\n",
        "      out_src, out_cls = D(x_real)\n",
        "      d_loss_real = - torch.mean(out_src)\n",
        "      d_loss_cls  = classification_loss(out_cls, label_org)\n",
        "\n",
        "      ## Generated data points\n",
        "      with torch.no_grad():\n",
        "        x_fake = G(x_real, c_trg)\n",
        "      out_src, _ = D(x_fake, classify=False)\n",
        "      d_loss_fake = torch.mean(out_src)\n",
        "\n",
        "      ## Gradient Penalty\n",
        "      alpha = torch.rand(x_real.size(0), 1, 1, 1, 1, device=device)\n",
        "      x_hat = (alpha * x_real.data + (1 - alpha) * x_fake.data).requires_grad_(True)\n",
        "      out_src, _ = D(x_hat, classify=False)\n",
        "      d_loss_gp = gradient_penalty(out_src, x_hat)\n",
        "\n",
        "      d_loss = d_loss_real + d_loss_fake + (lambda_gp * d_loss_gp) + (lambda_cls * d_loss_cls)\n",
        "\n",
        "      d_loss.backward()\n",
        "      # torch.nn.utils.clip_grad_norm_(D.parameters(), clipping_value)\n",
        "      if apply_grad == 0:\n",
        "        print(\"Applying gradients\")\n",
        "        D_optim.step()\n",
        "        G_optim.step()\n",
        "        D_optim.zero_grad()\n",
        "        G_optim.zero_grad()\n",
        "\n",
        "      tag = \"D-step\"\n",
        "      mode_flag = (d_loss_fake >= 0)\n",
        "\n",
        "    else:\n",
        "      #### TRAINING THE GENERATOR\n",
        "      ## Fooling the Discriminator loss\n",
        "      x_fake = G(x_real, c_trg)\n",
        "      out_src, out_cls = D(x_fake)\n",
        "      g_loss_fake = - torch.mean(out_src)\n",
        "      g_loss_cls = classification_loss(out_cls, label_trg)\n",
        "\n",
        "      # indices = (label_org == label_trg)\n",
        "      # if indices.sum() > 0:\n",
        "      #   g_loss_recon = torch.sum(torch.abs(x_real[indices] - x_fake[indices])) / indices.sum()\n",
        "\n",
        "      ## Reconstruction loss\n",
        "      # x_recon = G(x_fake, c_org)\n",
        "      # g_loss_recon = torch.sum(torch.abs(x_real - x_recon)) / batch_size\n",
        "\n",
        "      g_loss = g_loss_fake + (lambda_cls * g_loss_cls)\n",
        "      # g_loss = (g_loss_recon * lambda_recon) + g_loss_fake + (lambda_cls * g_loss_cls)\n",
        "\n",
        "      g_loss.backward()\n",
        "\n",
        "      # torch.nn.utils.clip_grad_norm_(G.parameters(), clipping_value)\n",
        "      if apply_grad == 0:\n",
        "        print(\"Applying gradients\")\n",
        "        G_optim.step()\n",
        "        D_optim.step()\n",
        "        G_optim.zero_grad()\n",
        "        D_optim.zero_grad()\n",
        "\n",
        "      tag = \"G-step\"\n",
        "      mode_flag = (g_loss < 0)\n",
        "\n",
        "    print(f\"{tag}  \" + \n",
        "          f\"D_loss_real: {d_loss_real:.4f}, \" +\n",
        "          f\"D_loss_fake: {d_loss_fake:.4f}, \" + \n",
        "          f\"D_loss_cls: {d_loss_cls:.4f}, \" + \n",
        "          f\"G_loss_fake: {g_loss_fake:.4f}, \" +\n",
        "          f\"G_loss_cls:  {g_loss_cls:.4f},  \" +\n",
        "          f\"G_loss_recon: {g_loss_recon:.4f}\")\n",
        "\n",
        "    file_count += batch_size\n",
        "    gen_count = (gen_count + 1) % 50\n",
        "    save_count = (save_count + 1) % 20\n",
        "    apply_grad = (apply_grad + 1) % accumulate"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYjgYjBU0-yM"
      },
      "source": [
        "## How to interpret the loss\n",
        "\n",
        "```D_loss_real``` $ << 0$ (Ideally)\n",
        "\n",
        "```D_loss_fake``` $ << 0$ (Ideally)\n",
        "\n",
        "```G_loss_fake``` $ << 0$ (Ideally)\n",
        "\n",
        "```G_loss_recon``` Must be small\n",
        "\n",
        "```G_loss_cls``` Must be small"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bdyFIcEUGTz",
        "outputId": "b6690992-d623-4566-c5c1-a93b5504aeb2"
      },
      "source": [
        "train(batch_size=64, lambda_cls=10, lambda_recon=10, accumulate=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "D-step  D_loss_real: -43.5539, D_loss_fake: -5.7336, D_loss_cls: 0.4982, G_loss_fake: 0.0000, G_loss_cls:  0.0000,  G_loss_recon: 0.0000\n",
            "G-step  D_loss_real: -43.5539, D_loss_fake: -5.7336, D_loss_cls: 0.4982, G_loss_fake: 4.7542, G_loss_cls:  0.0254,  G_loss_recon: 0.0000\n",
            "G-step  D_loss_real: -43.5539, D_loss_fake: -5.7336, D_loss_cls: 0.4982, G_loss_fake: -0.7236, G_loss_cls:  0.0242,  G_loss_recon: 0.0000\n",
            "D-step  D_loss_real: -43.6462, D_loss_fake: -0.0915, D_loss_cls: 0.5127, G_loss_fake: -0.7236, G_loss_cls:  0.0242,  G_loss_recon: 0.0000\n",
            "Applying gradients\n",
            "G-step  D_loss_real: -43.6462, D_loss_fake: -0.0915, D_loss_cls: 0.5127, G_loss_fake: 0.0846, G_loss_cls:  0.0347,  G_loss_recon: 0.0000\n",
            "G-step  D_loss_real: -43.6462, D_loss_fake: -0.0915, D_loss_cls: 0.5127, G_loss_fake: -3.3558, G_loss_cls:  0.0691,  G_loss_recon: 0.0000\n",
            "D-step  D_loss_real: -45.8130, D_loss_fake: 3.2365, D_loss_cls: 0.2203, G_loss_fake: -3.3558, G_loss_cls:  0.0691,  G_loss_recon: 0.0000\n",
            "D-step  D_loss_real: -50.0780, D_loss_fake: 4.7744, D_loss_cls: 0.2963, G_loss_fake: -3.3558, G_loss_cls:  0.0691,  G_loss_recon: 0.0000\n",
            "D-step  D_loss_real: -42.8206, D_loss_fake: 5.1316, D_loss_cls: 0.1846, G_loss_fake: -3.3558, G_loss_cls:  0.0691,  G_loss_recon: 0.0000\n",
            "Applying gradients\n",
            "D-step  D_loss_real: -45.3601, D_loss_fake: -0.6491, D_loss_cls: 0.0945, G_loss_fake: -3.3558, G_loss_cls:  0.0691,  G_loss_recon: 0.0000\n",
            "G-step  D_loss_real: -45.3601, D_loss_fake: -0.6491, D_loss_cls: 0.0945, G_loss_fake: -5.5230, G_loss_cls:  0.0378,  G_loss_recon: 0.0000\n",
            "D-step  D_loss_real: -54.1473, D_loss_fake: -0.8540, D_loss_cls: 0.1063, G_loss_fake: -5.5230, G_loss_cls:  0.0378,  G_loss_recon: 0.0000\n",
            "G-step  D_loss_real: -54.1473, D_loss_fake: -0.8540, D_loss_cls: 0.1063, G_loss_fake: -4.8991, G_loss_cls:  0.0507,  G_loss_recon: 0.0000\n",
            "D-step  D_loss_real: -50.7515, D_loss_fake: 5.4232, D_loss_cls: 0.6367, G_loss_fake: -4.8991, G_loss_cls:  0.0507,  G_loss_recon: 0.0000\n",
            "Applying gradients\n",
            "D-step  D_loss_real: -46.5058, D_loss_fake: -2.3451, D_loss_cls: 0.1063, G_loss_fake: -4.8991, G_loss_cls:  0.0507,  G_loss_recon: 0.0000\n",
            "G-step  D_loss_real: -46.5058, D_loss_fake: -2.3451, D_loss_cls: 0.1063, G_loss_fake: -2.8015, G_loss_cls:  0.0172,  G_loss_recon: 0.0000\n",
            "D-step  D_loss_real: -56.1578, D_loss_fake: -0.4412, D_loss_cls: 1.2027, G_loss_fake: -2.8015, G_loss_cls:  0.0172,  G_loss_recon: 0.0000\n",
            "G-step  D_loss_real: -56.1578, D_loss_fake: -0.4412, D_loss_cls: 1.2027, G_loss_fake: 3.4528, G_loss_cls:  0.0189,  G_loss_recon: 0.0000\n",
            "G-step  D_loss_real: -56.1578, D_loss_fake: -0.4412, D_loss_cls: 1.2027, G_loss_fake: 11.5062, G_loss_cls:  0.0094,  G_loss_recon: 0.0000\n",
            "Saving model\n",
            "Applying gradients\n",
            "G-step  D_loss_real: -56.1578, D_loss_fake: -0.4412, D_loss_cls: 1.2027, G_loss_fake: -3.1963, G_loss_cls:  0.0142,  G_loss_recon: 0.0000\n",
            "D-step  D_loss_real: -60.7491, D_loss_fake: 8.4785, D_loss_cls: 1.6888, G_loss_fake: -3.1963, G_loss_cls:  0.0142,  G_loss_recon: 0.0000\n",
            "D-step  D_loss_real: -53.0860, D_loss_fake: 3.6079, D_loss_cls: 0.1269, G_loss_fake: -3.1963, G_loss_cls:  0.0142,  G_loss_recon: 0.0000\n",
            "D-step  D_loss_real: -59.5445, D_loss_fake: 6.7671, D_loss_cls: 0.1074, G_loss_fake: -3.1963, G_loss_cls:  0.0142,  G_loss_recon: 0.0000\n",
            "D-step  D_loss_real: -59.9083, D_loss_fake: 3.7192, D_loss_cls: 1.9219, G_loss_fake: -3.1963, G_loss_cls:  0.0142,  G_loss_recon: 0.0000\n",
            "Applying gradients\n",
            "D-step  D_loss_real: -57.4272, D_loss_fake: 3.2198, D_loss_cls: 2.8524, G_loss_fake: -3.1963, G_loss_cls:  0.0142,  G_loss_recon: 0.0000\n",
            "D-step  D_loss_real: -62.0461, D_loss_fake: 8.1079, D_loss_cls: 0.6305, G_loss_fake: -3.1963, G_loss_cls:  0.0142,  G_loss_recon: 0.0000\n",
            "D-step  D_loss_real: -62.9900, D_loss_fake: 8.7865, D_loss_cls: 0.3452, G_loss_fake: -3.1963, G_loss_cls:  0.0142,  G_loss_recon: 0.0000\n",
            "D-step  D_loss_real: -60.5050, D_loss_fake: 7.4151, D_loss_cls: 0.1917, G_loss_fake: -3.1963, G_loss_cls:  0.0142,  G_loss_recon: 0.0000\n",
            "D-step  D_loss_real: -66.1483, D_loss_fake: 3.6735, D_loss_cls: 1.2586, G_loss_fake: -3.1963, G_loss_cls:  0.0142,  G_loss_recon: 0.0000\n",
            "Applying gradients\n",
            "D-step  D_loss_real: -62.0414, D_loss_fake: 8.0671, D_loss_cls: 1.3091, G_loss_fake: -3.1963, G_loss_cls:  0.0142,  G_loss_recon: 0.0000\n",
            "D-step  D_loss_real: -64.1721, D_loss_fake: 8.7890, D_loss_cls: 0.5491, G_loss_fake: -3.1963, G_loss_cls:  0.0142,  G_loss_recon: 0.0000\n",
            "D-step  D_loss_real: -61.2596, D_loss_fake: 6.3002, D_loss_cls: 0.6965, G_loss_fake: -3.1963, G_loss_cls:  0.0142,  G_loss_recon: 0.0000\n",
            "D-step  D_loss_real: -65.8202, D_loss_fake: 2.2628, D_loss_cls: 0.1333, G_loss_fake: -3.1963, G_loss_cls:  0.0142,  G_loss_recon: 0.0000\n",
            "D-step  D_loss_real: -63.8265, D_loss_fake: 3.9423, D_loss_cls: 0.6849, G_loss_fake: -3.1963, G_loss_cls:  0.0142,  G_loss_recon: 0.0000\n",
            "Applying gradients\n",
            "D-step  D_loss_real: -63.4911, D_loss_fake: 5.0295, D_loss_cls: 0.2198, G_loss_fake: -3.1963, G_loss_cls:  0.0142,  G_loss_recon: 0.0000\n",
            "D-step  D_loss_real: -69.7688, D_loss_fake: -3.2802, D_loss_cls: 0.0413, G_loss_fake: -3.1963, G_loss_cls:  0.0142,  G_loss_recon: 0.0000\n",
            "G-step  D_loss_real: -69.7688, D_loss_fake: -3.2802, D_loss_cls: 0.0413, G_loss_fake: -2.6414, G_loss_cls:  0.0590,  G_loss_recon: 0.0000\n",
            "D-step  D_loss_real: -67.1625, D_loss_fake: 3.4580, D_loss_cls: 0.4823, G_loss_fake: -2.6414, G_loss_cls:  0.0590,  G_loss_recon: 0.0000\n",
            "D-step  D_loss_real: -67.5101, D_loss_fake: 4.2316, D_loss_cls: 0.2080, G_loss_fake: -2.6414, G_loss_cls:  0.0590,  G_loss_recon: 0.0000\n",
            "Saving model\n",
            "Applying gradients\n",
            "D-step  D_loss_real: -67.3104, D_loss_fake: -1.0206, D_loss_cls: 0.1461, G_loss_fake: -2.6414, G_loss_cls:  0.0590,  G_loss_recon: 0.0000\n",
            "G-step  D_loss_real: -67.3104, D_loss_fake: -1.0206, D_loss_cls: 0.1461, G_loss_fake: -4.2380, G_loss_cls:  0.1916,  G_loss_recon: 0.0000\n",
            "D-step  D_loss_real: -65.2905, D_loss_fake: -0.7445, D_loss_cls: 0.2693, G_loss_fake: -4.2380, G_loss_cls:  0.1916,  G_loss_recon: 0.0000\n",
            "G-step  D_loss_real: -65.2905, D_loss_fake: -0.7445, D_loss_cls: 0.2693, G_loss_fake: -6.8512, G_loss_cls:  0.2889,  G_loss_recon: 0.0000\n",
            "D-step  D_loss_real: -67.2356, D_loss_fake: 1.7805, D_loss_cls: 0.1846, G_loss_fake: -6.8512, G_loss_cls:  0.2889,  G_loss_recon: 0.0000\n",
            "Applying gradients\n",
            "D-step  D_loss_real: -64.2976, D_loss_fake: 1.4837, D_loss_cls: 0.3304, G_loss_fake: -6.8512, G_loss_cls:  0.2889,  G_loss_recon: 0.0000\n",
            "D-step  D_loss_real: -69.3149, D_loss_fake: 3.4531, D_loss_cls: 1.2391, G_loss_fake: -6.8512, G_loss_cls:  0.2889,  G_loss_recon: 0.0000\n",
            "D-step  D_loss_real: -69.0928, D_loss_fake: 3.1082, D_loss_cls: 0.5400, G_loss_fake: -6.8512, G_loss_cls:  0.2889,  G_loss_recon: 0.0000\n",
            "D-step  D_loss_real: -73.6875, D_loss_fake: 4.1885, D_loss_cls: 0.7581, G_loss_fake: -6.8512, G_loss_cls:  0.2889,  G_loss_recon: 0.0000\n",
            "D-step  D_loss_real: -71.3611, D_loss_fake: 0.0676, D_loss_cls: 2.7496, G_loss_fake: -6.8512, G_loss_cls:  0.2889,  G_loss_recon: 0.0000\n",
            "Applying gradients\n",
            "D-step  D_loss_real: -68.0189, D_loss_fake: 2.5318, D_loss_cls: 0.8936, G_loss_fake: -6.8512, G_loss_cls:  0.2889,  G_loss_recon: 0.0000\n",
            "D-step  D_loss_real: -80.8763, D_loss_fake: -0.0017, D_loss_cls: 0.2778, G_loss_fake: -6.8512, G_loss_cls:  0.2889,  G_loss_recon: 0.0000\n",
            "G-step  D_loss_real: -80.8763, D_loss_fake: -0.0017, D_loss_cls: 0.2778, G_loss_fake: -3.2354, G_loss_cls:  0.0456,  G_loss_recon: 0.0000\n",
            "D-step  D_loss_real: -69.6422, D_loss_fake: 0.5491, D_loss_cls: 1.6629, G_loss_fake: -3.2354, G_loss_cls:  0.0456,  G_loss_recon: 0.0000\n",
            "D-step  D_loss_real: -71.3072, D_loss_fake: 2.9502, D_loss_cls: 0.3328, G_loss_fake: -3.2354, G_loss_cls:  0.0456,  G_loss_recon: 0.0000\n",
            "Applying gradients\n",
            "D-step  D_loss_real: -75.5145, D_loss_fake: 4.9918, D_loss_cls: 0.7490, G_loss_fake: -3.2354, G_loss_cls:  0.0456,  G_loss_recon: 0.0000\n",
            "D-step  D_loss_real: -75.6416, D_loss_fake: -2.5467, D_loss_cls: 0.7736, G_loss_fake: -3.2354, G_loss_cls:  0.0456,  G_loss_recon: 0.0000\n",
            "G-step  D_loss_real: -75.6416, D_loss_fake: -2.5467, D_loss_cls: 0.7736, G_loss_fake: 3.2021, G_loss_cls:  1.8907,  G_loss_recon: 0.0000\n",
            "G-step  D_loss_real: -75.6416, D_loss_fake: -2.5467, D_loss_cls: 0.7736, G_loss_fake: 6.1275, G_loss_cls:  0.4096,  G_loss_recon: 0.0000\n",
            "G-step  D_loss_real: -75.6416, D_loss_fake: -2.5467, D_loss_cls: 0.7736, G_loss_fake: -1.3446, G_loss_cls:  0.9134,  G_loss_recon: 0.0000\n",
            "Saving model\n",
            "Applying gradients\n",
            "G-step  D_loss_real: -75.6416, D_loss_fake: -2.5467, D_loss_cls: 0.7736, G_loss_fake: 6.2569, G_loss_cls:  0.1824,  G_loss_recon: 0.0000\n",
            "G-step  D_loss_real: -75.6416, D_loss_fake: -2.5467, D_loss_cls: 0.7736, G_loss_fake: -2.0294, G_loss_cls:  0.0046,  G_loss_recon: 0.0000\n",
            "D-step  D_loss_real: -80.7573, D_loss_fake: 0.1608, D_loss_cls: 0.2564, G_loss_fake: -2.0294, G_loss_cls:  0.0046,  G_loss_recon: 0.0000\n",
            "D-step  D_loss_real: -74.8679, D_loss_fake: -1.8807, D_loss_cls: 0.2785, G_loss_fake: -2.0294, G_loss_cls:  0.0046,  G_loss_recon: 0.0000\n",
            "G-step  D_loss_real: -74.8679, D_loss_fake: -1.8807, D_loss_cls: 0.2785, G_loss_fake: 4.0899, G_loss_cls:  0.0016,  G_loss_recon: 0.0000\n",
            "Applying gradients\n",
            "G-step  D_loss_real: -74.8679, D_loss_fake: -1.8807, D_loss_cls: 0.2785, G_loss_fake: -0.0480, G_loss_cls:  0.0026,  G_loss_recon: 0.0000\n",
            "D-step  D_loss_real: -77.9491, D_loss_fake: -2.0455, D_loss_cls: 0.4114, G_loss_fake: -0.0480, G_loss_cls:  0.0026,  G_loss_recon: 0.0000\n",
            "G-step  D_loss_real: -77.9491, D_loss_fake: -2.0455, D_loss_cls: 0.4114, G_loss_fake: 0.1913, G_loss_cls:  0.4704,  G_loss_recon: 0.0000\n",
            "G-step  D_loss_real: -77.9491, D_loss_fake: -2.0455, D_loss_cls: 0.4114, G_loss_fake: 3.4370, G_loss_cls:  0.2319,  G_loss_recon: 0.0000\n",
            "G-step  D_loss_real: -77.9491, D_loss_fake: -2.0455, D_loss_cls: 0.4114, G_loss_fake: 6.4203, G_loss_cls:  0.2578,  G_loss_recon: 0.0000\n",
            "Applying gradients\n",
            "G-step  D_loss_real: -77.9491, D_loss_fake: -2.0455, D_loss_cls: 0.4114, G_loss_fake: 5.6890, G_loss_cls:  0.1717,  G_loss_recon: 0.0000\n",
            "G-step  D_loss_real: -77.9491, D_loss_fake: -2.0455, D_loss_cls: 0.4114, G_loss_fake: -0.0908, G_loss_cls:  0.0132,  G_loss_recon: 0.0000\n",
            "G-step  D_loss_real: -77.9491, D_loss_fake: -2.0455, D_loss_cls: 0.4114, G_loss_fake: 0.8767, G_loss_cls:  0.0107,  G_loss_recon: 0.0000\n",
            "G-step  D_loss_real: -77.9491, D_loss_fake: -2.0455, D_loss_cls: 0.4114, G_loss_fake: -3.4546, G_loss_cls:  0.0095,  G_loss_recon: 0.0000\n",
            "D-step  D_loss_real: -86.1050, D_loss_fake: 3.3067, D_loss_cls: 0.8268, G_loss_fake: -3.4546, G_loss_cls:  0.0095,  G_loss_recon: 0.0000\n",
            "Applying gradients\n",
            "D-step  D_loss_real: -83.5993, D_loss_fake: 0.8790, D_loss_cls: 0.8005, G_loss_fake: -3.4546, G_loss_cls:  0.0095,  G_loss_recon: 0.0000\n",
            "D-step  D_loss_real: -91.6470, D_loss_fake: 7.5925, D_loss_cls: 0.1847, G_loss_fake: -3.4546, G_loss_cls:  0.0095,  G_loss_recon: 0.0000\n",
            "D-step  D_loss_real: -86.3769, D_loss_fake: 12.4371, D_loss_cls: 0.3326, G_loss_fake: -3.4546, G_loss_cls:  0.0095,  G_loss_recon: 0.0000\n",
            "D-step  D_loss_real: -83.2180, D_loss_fake: 7.8099, D_loss_cls: 0.2582, G_loss_fake: -3.4546, G_loss_cls:  0.0095,  G_loss_recon: 0.0000\n",
            "D-step  D_loss_real: -91.8520, D_loss_fake: 5.3128, D_loss_cls: 1.2134, G_loss_fake: -3.4546, G_loss_cls:  0.0095,  G_loss_recon: 0.0000\n",
            "Saving model\n",
            "Applying gradients\n",
            "D-step  D_loss_real: -89.8569, D_loss_fake: 6.5082, D_loss_cls: 0.8405, G_loss_fake: -3.4546, G_loss_cls:  0.0095,  G_loss_recon: 0.0000\n",
            "D-step  D_loss_real: -78.7083, D_loss_fake: 15.5118, D_loss_cls: 1.0109, G_loss_fake: -3.4546, G_loss_cls:  0.0095,  G_loss_recon: 0.0000\n",
            "D-step  D_loss_real: -91.6578, D_loss_fake: 11.4667, D_loss_cls: 0.0531, G_loss_fake: -3.4546, G_loss_cls:  0.0095,  G_loss_recon: 0.0000\n",
            "D-step  D_loss_real: -94.0900, D_loss_fake: 13.6657, D_loss_cls: 1.0335, G_loss_fake: -3.4546, G_loss_cls:  0.0095,  G_loss_recon: 0.0000\n",
            "D-step  D_loss_real: -88.4330, D_loss_fake: 9.1604, D_loss_cls: 0.3222, G_loss_fake: -3.4546, G_loss_cls:  0.0095,  G_loss_recon: 0.0000\n",
            "Applying gradients\n",
            "D-step  D_loss_real: -87.8251, D_loss_fake: 10.8840, D_loss_cls: 0.3261, G_loss_fake: -3.4546, G_loss_cls:  0.0095,  G_loss_recon: 0.0000\n",
            "D-step  D_loss_real: -96.2172, D_loss_fake: 26.2831, D_loss_cls: 0.5300, G_loss_fake: -3.4546, G_loss_cls:  0.0095,  G_loss_recon: 0.0000\n",
            "D-step  D_loss_real: -93.2799, D_loss_fake: 18.2886, D_loss_cls: 0.4265, G_loss_fake: -3.4546, G_loss_cls:  0.0095,  G_loss_recon: 0.0000\n",
            "D-step  D_loss_real: -88.7869, D_loss_fake: 7.7314, D_loss_cls: 0.6309, G_loss_fake: -3.4546, G_loss_cls:  0.0095,  G_loss_recon: 0.0000\n",
            "D-step  D_loss_real: -96.6605, D_loss_fake: 22.7820, D_loss_cls: 0.5649, G_loss_fake: -3.4546, G_loss_cls:  0.0095,  G_loss_recon: 0.0000\n",
            "Applying gradients\n",
            "D-step  D_loss_real: -91.2511, D_loss_fake: 15.6135, D_loss_cls: 0.5522, G_loss_fake: -3.4546, G_loss_cls:  0.0095,  G_loss_recon: 0.0000\n",
            "D-step  D_loss_real: -96.4188, D_loss_fake: 9.3471, D_loss_cls: 0.2326, G_loss_fake: -3.4546, G_loss_cls:  0.0095,  G_loss_recon: 0.0000\n",
            "D-step  D_loss_real: -98.1998, D_loss_fake: 18.9784, D_loss_cls: 0.3349, G_loss_fake: -3.4546, G_loss_cls:  0.0095,  G_loss_recon: 0.0000\n",
            "D-step  D_loss_real: -97.8567, D_loss_fake: 12.9274, D_loss_cls: 0.2180, G_loss_fake: -3.4546, G_loss_cls:  0.0095,  G_loss_recon: 0.0000\n",
            "D-step  D_loss_real: -99.4392, D_loss_fake: 19.2009, D_loss_cls: 0.8274, G_loss_fake: -3.4546, G_loss_cls:  0.0095,  G_loss_recon: 0.0000\n",
            "Applying gradients\n",
            "D-step  D_loss_real: -99.7137, D_loss_fake: 12.7683, D_loss_cls: 0.3199, G_loss_fake: -3.4546, G_loss_cls:  0.0095,  G_loss_recon: 0.0000\n",
            "D-step  D_loss_real: -105.4473, D_loss_fake: 14.1621, D_loss_cls: 0.7172, G_loss_fake: -3.4546, G_loss_cls:  0.0095,  G_loss_recon: 0.0000\n",
            "D-step  D_loss_real: -88.9411, D_loss_fake: 12.9624, D_loss_cls: 0.1920, G_loss_fake: -3.4546, G_loss_cls:  0.0095,  G_loss_recon: 0.0000\n",
            "D-step  D_loss_real: -97.2865, D_loss_fake: 4.6069, D_loss_cls: 0.5213, G_loss_fake: -3.4546, G_loss_cls:  0.0095,  G_loss_recon: 0.0000\n",
            "D-step  D_loss_real: -99.8720, D_loss_fake: 15.4242, D_loss_cls: 0.2605, G_loss_fake: -3.4546, G_loss_cls:  0.0095,  G_loss_recon: 0.0000\n",
            "Saving model\n",
            "Applying gradients\n",
            "D-step  D_loss_real: -101.9591, D_loss_fake: 15.1472, D_loss_cls: 1.1001, G_loss_fake: -3.4546, G_loss_cls:  0.0095,  G_loss_recon: 0.0000\n",
            "D-step  D_loss_real: -98.3486, D_loss_fake: 3.3561, D_loss_cls: 0.5373, G_loss_fake: -3.4546, G_loss_cls:  0.0095,  G_loss_recon: 0.0000\n",
            "D-step  D_loss_real: -97.1491, D_loss_fake: 17.1526, D_loss_cls: 0.2109, G_loss_fake: -3.4546, G_loss_cls:  0.0095,  G_loss_recon: 0.0000\n",
            "D-step  D_loss_real: -103.2122, D_loss_fake: 16.0532, D_loss_cls: 0.2428, G_loss_fake: -3.4546, G_loss_cls:  0.0095,  G_loss_recon: 0.0000\n",
            "D-step  D_loss_real: -102.1498, D_loss_fake: 7.5271, D_loss_cls: 0.1965, G_loss_fake: -3.4546, G_loss_cls:  0.0095,  G_loss_recon: 0.0000\n",
            "Applying gradients\n",
            "D-step  D_loss_real: -101.7265, D_loss_fake: 11.7579, D_loss_cls: 0.6652, G_loss_fake: -3.4546, G_loss_cls:  0.0095,  G_loss_recon: 0.0000\n",
            "D-step  D_loss_real: -104.3129, D_loss_fake: -2.8349, D_loss_cls: 0.1130, G_loss_fake: -3.4546, G_loss_cls:  0.0095,  G_loss_recon: 0.0000\n",
            "G-step  D_loss_real: -104.3129, D_loss_fake: -2.8349, D_loss_cls: 0.1130, G_loss_fake: -6.2809, G_loss_cls:  0.0266,  G_loss_recon: 0.0000\n",
            "D-step  D_loss_real: -102.3350, D_loss_fake: -2.2693, D_loss_cls: 0.2123, G_loss_fake: -6.2809, G_loss_cls:  0.0266,  G_loss_recon: 0.0000\n",
            "G-step  D_loss_real: -102.3350, D_loss_fake: -2.2693, D_loss_cls: 0.2123, G_loss_fake: -4.9597, G_loss_cls:  0.1233,  G_loss_recon: 0.0000\n",
            "Applying gradients\n",
            "D-step  D_loss_real: -106.3049, D_loss_fake: 10.5533, D_loss_cls: 0.5114, G_loss_fake: -4.9597, G_loss_cls:  0.1233,  G_loss_recon: 0.0000\n",
            "D-step  D_loss_real: -108.8742, D_loss_fake: 16.8671, D_loss_cls: 0.3801, G_loss_fake: -4.9597, G_loss_cls:  0.1233,  G_loss_recon: 0.0000\n",
            "D-step  D_loss_real: -108.0420, D_loss_fake: 17.1058, D_loss_cls: 0.1559, G_loss_fake: -4.9597, G_loss_cls:  0.1233,  G_loss_recon: 0.0000\n",
            "D-step  D_loss_real: -104.7062, D_loss_fake: 10.7417, D_loss_cls: 0.4577, G_loss_fake: -4.9597, G_loss_cls:  0.1233,  G_loss_recon: 0.0000\n",
            "D-step  D_loss_real: -106.4966, D_loss_fake: 7.5909, D_loss_cls: 0.2419, G_loss_fake: -4.9597, G_loss_cls:  0.1233,  G_loss_recon: 0.0000\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}